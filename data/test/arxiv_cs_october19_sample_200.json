[{"id":1910.00888,"authors":"Thomas Pinetz, Daniel Soukup and Thomas Pock","title":"On the estimation of the Wasserstein distance in generative models","abstract":"Generative Adversarial Networks (GANs) have been used to model the underlying probability distribution of sample based datasets. GANs are notoriuos for training difficulties and their dependence on arbitrary hyperparameters. One recent improvement in GAN literature is to use the Wasserstein distance as loss function leading to Wasserstein Generative Adversarial Networks (WGANs). Using this as a basis, we show various ways in which the Wasserstein distance is estimated for the task of generative modelling. Additionally, the secrets in training such models are shown and summarized at the end of this work. Where applicable, we extend current works to different algorithms, different cost functions, and different regularization schemes to improve generative models.","categories":"cs.LG stat.ML","primary_cat":"cs.LG"},{"id":1910.07236,"authors":"Nikolay Jetchev, Urs Bergmann, G\\\"okhan Yildirim","title":"Transform the Set: Memory Attentive Generation of Guided and Unguided   Image Collages","abstract":"Cutting and pasting image segments feels intuitive: the choice of source templates gives artists flexibility in recombining existing source material. Formally, this process takes an image set as input and outputs a collage of the set elements. Such selection from sets of source templates does not fit easily in classical convolutional neural models requiring inputs of fixed size. Inspired by advances in attention and set-input machine learning, we present a novel architecture that can generate in one forward pass image collages of source templates using set-structured representations. This paper has the following contributions: (i) a novel framework for image generation called Memory Attentive Generation of Image Collages (MAGIC) which gives artists new ways to create digital collages; (ii) from the machine-learning perspective, we show a novel Generative Adversarial Networks (GAN) architecture that uses Set-Transformer layers and set-pooling to blend sets of random image samples - a hybrid non-parametric approach.","categories":"cs.CV cs.LG eess.IV stat.ML","primary_cat":"cs.CV"},{"id":1910.02613,"authors":"Weihan Chen, Xia Yin, Zhiliang Wang, Xingang Shi","title":"Placement and Routing Optimization Problem for Service Function Chain:   State of Art and Future Opportunities","abstract":"Network Functions Virtualization (NFV) allows implantation of network functions to be independent of dedicated hardware devices. Any series of services can be represented by a service function chain which contains a set of virtualized network functions in a specified order. From the perspective of network performance optimization, the challenges of deploying service chain in network is twofold: 1) the location of placing virtualized network functions and resources allocation scheme; and 2) routing policy for traffic flow among different instances of network function. This article introduces service function chain related optimization problems, summarizes the optimization motivation and mainstream algorithm of virtualized network functions deployment and traffic routing. We hope it can help readers to learn about the current research progress and make further innovation in this field.","categories":"cs.NI","primary_cat":"cs.NI"},{"id":1910.09753,"authors":"Adam Fisch, Alon Talmor, Robin Jia, Minjoon Seo, Eunsol Choi, Danqi\n  Chen","title":"MRQA 2019 Shared Task: Evaluating Generalization in Reading   Comprehension","abstract":"We present the results of the Machine Reading for Question Answering (MRQA) 2019 shared task on evaluating the generalization capabilities of reading comprehension systems. In this task, we adapted and unified 18 distinct question answering datasets into the same format. Among them, six datasets were made available for training, six datasets were made available for development, and the final six were hidden for final evaluation. Ten teams submitted systems, which explored various ideas including data sampling, multi-task learning, adversarial training and ensembling. The best system achieved an average F1 score of 72.5 on the 12 held-out datasets, 10.7 absolute points higher than our initial baseline based on BERT.","categories":"cs.CL","primary_cat":"cs.CL"},{"id":1910.02445,"authors":"Christoph Heindl, Markus Ikeda, Gernot St\\\"ubl, Andreas Pichler, Josef\n  Scharinger","title":"Enhanced Human-Machine Interaction by Combining Proximity Sensing with   Global Perception","abstract":"The raise of collaborative robotics has led to wide range of sensor technologies to detect human-machine interactions: at short distances, proximity sensors detect nontactile gestures virtually occlusion-free, while at medium distances, active depth sensors are frequently used to infer human intentions. We describe an optical system for large workspaces to capture human pose based on a single panoramic color camera. Despite the two-dimensional input, our system is able to predict metric 3D pose information over larger field of views than would be possible with active depth measurement cameras. We merge posture context with proximity perception to reduce occlusions and improve accuracy at long distances. We demonstrate the capabilities of our system in two use cases involving multiple humans and robots.","categories":"cs.CV cs.HC cs.RO","primary_cat":"cs.CV"},{"id":1910.104,"authors":"Manuel Pariente, Samuele Cornell, Antoine Deleforge and Emmanuel\n  Vincent","title":"Filterbank design for end-to-end speech separation","abstract":"Single-channel speech separation has recently made great progress thanks to learned filterbanks as used in ConvTasNet. In parallel, parameterized filterbanks have been proposed for speaker recognition where only center frequencies and bandwidths are learned. In this work, we extend real-valued learned and parameterized filterbanks into complex-valued analytic filterbanks and define a set of corresponding representations and masking strategies. We evaluate these filterbanks on a newly released noisy speech separation dataset (WHAM). The results show that the proposed analytic learned filterbank consistently outperforms the real-valued filterbank of ConvTasNet. Also, we validate the use of parameterized filterbanks and show that complex-valued representations and masks are beneficial in all conditions. Finally, we show that the STFT achieves its best performance for 2ms windows.","categories":"cs.SD cs.LG eess.AS eess.SP","primary_cat":"cs.SD"},{"id":1910.0033,"authors":"S. Soroush Haj Zargarbashi, Bagher Babaali","title":"A Multi-Modal Feature Embedding Approach to Diagnose Alzheimer Disease   from Spoken Language","abstract":"Introduction: Alzheimer's disease is a type of dementia in which early diagnosis plays a major rule in the quality of treatment. Among new works in the diagnosis of Alzheimer's disease, there are many of them analyzing the voice stream acoustically, syntactically or both. The mostly used tools to perform these analysis usually include machine learning techniques. Objective: Designing an automatic machine learning based diagnosis system will help in the procedure of early detection. Also, systems, using noninvasive data are preferable. Methods: We used are classification system based on spoken language. We use three (statistical and neural) approaches to classify audio signals from spoken language into two classes of dementia and control. Result: This work designs a multi-modal feature embedding on the spoken language audio signal using three approaches; N-gram, i-vector, and x-vector. The evaluation of the system is done on the cookie picture description task from Pitt Corpus dementia bank with the accuracy of 83:6","categories":"cs.LG cs.CL eess.AS stat.ML","primary_cat":"cs.LG"},{"id":1910.09808,"authors":"Lorenzo Gigoni, Alessandro Betti, Mauro Tucci and Emanuele Crisostomi","title":"A Scalable Predictive Maintenance Model for Detecting Wind Turbine   Component Failures Based on SCADA Data","abstract":"In this work, a novel predictive maintenance system is presented and applied to the main components of wind turbines. The proposed model is based on machine learning and statistical process control tools applied to SCADA (Supervisory Control And Data Acquisition) data of critical components. The test campaign was divided into two stages: a first two years long offline test, and a second one year long real-time test. The offline test used historical faults from six wind farms located in Italy and Romania, corresponding to a total of 150 wind turbines and an overall installed nominal power of 283 MW. The results demonstrate outstanding capabilities of anomaly prediction up to 2 months before device unscheduled downtime. Furthermore, the real-time 12-months test confirms the ability of the proposed system to detect several anomalies, therefore allowing the operators to identify the root causes, and to schedule maintenance actions before reaching a catastrophic stage.","categories":"cs.LG eess.SP","primary_cat":"cs.LG"},{"id":1910.0101,"authors":"Nassim Abderrahmane and Edgar Lemaire and Beno\\^it Miramond","title":"Design Space Exploration of Hardware Spiking Neurons for Embedded   Artificial Intelligence","abstract":"Machine learning is yielding unprecedented interest in research and industry, due to recent success in many applied contexts such as image classification and object recognition. However, the deployment of these systems requires huge computing capabilities, thus making them unsuitable for embedded systems. To deal with this limitation, many researchers are investigating brain-inspired computing, which would be a perfect alternative to the conventional Von Neumann architecture based computers (CPU\/GPU) that meet the requirements for computing performance, but not for energy-efficiency. Therefore, neuromorphic hardware circuits that are adaptable for both parallel and distributed computations need to be designed. In this paper, we focus on Spiking Neural Networks (SNNs) with a comprehensive study of information coding methods and hardware exploration. In this context, we propose a framework for neuromorphic hardware design space exploration, which allows to define a suitable architecture based on application-specific constraints and starting from a wide variety of possible architectural choices. For this framework, we have developed a behavioral level simulator for neuromorphic hardware architectural exploration named NAXT. Moreover, we propose modified versions of the standard Rate Coding technique to make trade-offs with the Time Coding paradigm, which is characterized by the low number of spikes propagating in the network. Thus, we are able to reduce the number of spikes while keeping the same neuron's model, which results in an SNN with fewer events to process. By doing so, we seek to reduce the amount of power consumed by the hardware. Furthermore, we present three neuromorphic hardware architectures in order to quantitatively study the implementation of SNNs. These architectures are derived from a novel funnel-like Design Space Exploration framework for neuromorphic hardware.","categories":"cs.NE","primary_cat":"cs.NE"},{"id":1910.01157,"authors":"Jeff Da and Jungo Kasai","title":"Cracking the Contextual Commonsense Code: Understanding Commonsense   Reasoning Aptitude of Deep Contextual Representations","abstract":"Pretrained deep contextual representations have advanced the state-of-the-art on various commonsense NLP tasks, but we lack a concrete understanding of the capability of these models. Thus, we investigate and challenge several aspects of BERT's commonsense representation abilities. First, we probe BERT's ability to classify various object attributes, demonstrating that BERT shows a strong ability in encoding various commonsense features in its embedding space, but is still deficient in many areas. Next, we show that, by augmenting BERT's pretraining data with additional data related to the deficient attributes, we are able to improve performance on a downstream commonsense reasoning task while using a minimal amount of data. Finally, we develop a method of fine-tuning knowledge graphs embeddings alongside BERT and show the continued importance of explicit knowledge graphs.","categories":"cs.CL","primary_cat":"cs.CL"},{"id":1910.07274,"authors":"Peter Boyvalenkov, Peter Dragnev, Douglas Hardin, Edward Saff, Maya\n  Stoyanova","title":"Universal Bounds for Size and Energy of Codes of Given Minimum and   Maximum Distances","abstract":"We employ signed measures that are positive definite up to certain degrees to establish Levenshtein-type upper bounds on the cardinality of codes with given minimum and maximum distances, and universal lower bounds on the potential energy (for absolutely monotone interactions) for codes with given maximum distance and cardinality. The distance distributions of codes that attain the bounds are found in terms of the parameters of Levenshtein-type quadrature formulas. Necessary and sufficient conditions for the optimality of our bounds are derived. Further, we obtain upper bounds on the energy of codes of fixed minimum and maximum distances and cardinality.","categories":"cs.IT math.CO math.IT","primary_cat":"cs.IT"},{"id":1910.05794,"authors":"Bertie Vidgen, Taha Yasseri, Helen Margetts","title":"Trajectories of Islamophobic hate amongst far right actors on Twitter","abstract":"Far right actors use the Internet for myriad purposes, such as forming communities, sharing information and attracting support. Concerns have been raised about their use of social media to spread hateful messages by both academics and policymakers. Given the potentially dangerous effects of hate speech, which can inflict harm on targeted victims, create a sense of fear amongst communities and pollute civic discourse, there is a pressing need to understand at a granular level how it manifests amongst far right actors online. In this paper we investigate the dynamics of Islamophobia amongst followers of a far right political party on Twitter, the British National Party. Using a new dataset of five million tweets, collected over a period of one year, we identify seven distinct trajectories of Islamophobia, which capture qualitative, qualitative and temporal differences in users' behaviour. We analyse the data using a classifier for Islamophobic content, which distinguishes between None, Implicit and Explicit Islamophobia, and latent Markov modelling with k modes clustering. The findings provide a new level of granular insight into Islamophobic behaviour amongst the far right on social media, both deepening existing knowledge and informing policy discussions regarding far right extremism and online hate speech.","categories":"cs.SI cs.CY physics.soc-ph stat.AP","primary_cat":"cs.SI"},{"id":1910.06302,"authors":"Erfan Noury, Suria S. Mannil, Robert T. Chang, An Ran Ran, Carol Y.\n  Cheung, Suman S. Thapa, Harsha L. Rao, Srilakshmi Dasari, Mohammed\n  Riyazuddin, Sriharsha Nagaraj, Reza Zadeh","title":"Detecting Glaucoma Using 3D Convolutional Neural Network of Raw SD-OCT   Optic Nerve Scans","abstract":"We propose developing and validating a three-dimensional (3D) deep learning system using the entire unprocessed OCT optic nerve volumes to distinguish true glaucoma from normals in order to discover any additional imaging biomarkers within the cube through saliency mapping. The algorithm has been validated against 4 additional distinct datasets from different countries using multimodal test results to define glaucoma rather than just the OCT alone.   2076 OCT (Cirrus SD-OCT, Carl Zeiss Meditec, Dublin, CA) cube scans centered over the optic nerve, of 879 eyes (390 healthy and 489 glaucoma) from 487 patients, age 18-84 years, were exported from the Glaucoma Clinic Imaging Database at the Byers Eye Institute, Stanford University, from March 2010 to December 2017. A 3D deep neural network was trained and tested on this unique OCT optic nerve head dataset from Stanford. A total of 3620 scans (all obtained using the Cirrus SD-OCT device) from 1458 eyes obtained from 4 different institutions, from United States (943 scans), Hong Kong (1625 scans), India (672 scans), and Nepal (380 scans) were used for external evaluation.   The 3D deep learning system achieved an area under the receiver operation characteristics curve (AUROC) of 0.8883 in the primary Stanford test set identifying true normal from true glaucoma. The system obtained AUROCs of 0.8571, 0.7695, 0.8706, and 0.7965 on OCT cubes from United States, Hong Kong, India, and Nepal, respectively.   We also analyzed the performance of the model separately for each myopia severity level as defined by spherical equivalent and the model was able to achieve F1 scores of 0.9673, 0.9491, and 0.8528 on severe, moderate, and mild myopia cases, respectively. Saliency map visualizations highlighted a significant association between the optic nerve lamina cribrosa region in the glaucoma group.","categories":"eess.IV cs.CV cs.LG","primary_cat":"eess.IV"},{"id":1910.09005,"authors":"Jacob Holm and Eva Rotenberg","title":"Worst-Case Polylog Incremental SPQR-trees: Embeddings, Planarity, and   Triconnectivity","abstract":"We show that every labelled planar graph $G$ can be assigned a canonical embedding $\\phi(G)$, such that for any planar $G'$ that differs from $G$ by the insertion or deletion of one edge, the number of local changes to the combinatorial embedding needed to get from $\\phi(G)$ to $\\phi(G')$ is $O(\\log n)$.   In contrast, there exist embedded graphs where $\\Omega(n)$ changes are necessary to accommodate one inserted edge. We provide a matching lower bound of $\\Omega(\\log n)$ local changes, and although our upper bound is worst-case, our lower bound hold in the amortized case as well.   Our proof is based on BC trees and SPQR trees, and we develop \\emph{pre-split} variants of these for general graphs, based on a novel biased heavy-path decomposition, where the structural changes corresponding to edge insertions and deletions in the underlying graph consist of at most $O(\\log n)$ basic operations of a particularly simple form.   As a secondary result, we show how to maintain the pre-split trees under edge insertions in the underlying graph deterministically in worst case $O(\\log^3 n)$ time. Using this, we obtain deterministic data structures for incremental planarity testing, incremental planar embedding, and incremental triconnectivity, that each have worst case $O(\\log^3 n)$ update and query time, answering an open question by La Poutr\\'e and Westbrook from 1998.","categories":"cs.DS","primary_cat":"cs.DS"},{"id":1910.07784,"authors":"Deepanwita Datta","title":"Indoor Information Retrieval using Lifelog Data","abstract":"Studying human behaviour through lifelogging has seen an increase in attention from researchers over the past decade. The opportunities that lifelogging offers are based on the fact that a lifelog, as a \"black box\" of our lives, offers rich contextual information, which has been an Achilles heel of information discovery. While lifelog data has been put to use in various contexts, its application to indoor environment scenario remains unexplored. In this proposal, I plan to design a method that enables us to capture and record indoor lifelog data of a person's life in order to facilitate healthcare systems, emergency response, item tracking etc. To this end, we aim to build an Indoor Information Retrieval system that can be queried with natural language queries over lifelog data. Judicious use of the lifelog data for the indoor application may enable us to solve very fundamental but non-avoidable problems of our daily life. Analysis of lifelog data coupled with Information Retrieval is not only a promising research topic, but the possibility of its indoor application especially for healthcare, lost-item tracking would be an innovative research idea to the best of our knowledge.","categories":"cs.IR cs.HC","primary_cat":"cs.IR"},{"id":1910.03784,"authors":"Kohei Suenaga and Takuya Ishizawa","title":"Generalized Property-Directed Reachability for Hybrid Systems","abstract":"Generalized property-directed reachability (GPDR) belongs to the family of the model-checking techniques called IC3\/PDR. It has been successfully applied to software verification; for example, it is the core of Spacer, a state-of-the-art Horn-clause solver bundled with Z3. However, it has yet to be applied to hybrid systems, which involve a continuous evolution of values over time. As the first step towards GPDR- based model checking for hybrid systems, this paper formalizes HGPDR, an adaptation of GPDR to hybrid systems, and proves its soundness. We also implemented a semi-automated proof-of-concept verifier, which allows a user to provide hints to guide verification steps.","categories":"cs.PL cs.SE","primary_cat":"cs.PL"},{"id":1910.02521,"authors":"G. Michele Pinna","title":"Representing Dependencies in Event Structures","abstract":"Event structures where the causality may explicitly change during a computation have recently gained the stage. In this kind of event structures the changes in the set of the causes of an event are triggered by modifiers that may add or remove dependencies, thus making the happening of an event contextual. Still the focus is always on the dependencies of the event. In this paper we promote the idea that the \\emph{context} determined by the modifiers plays a major role, and the context itself determines not only the causes but also what causality should be. Modifiers are then used to understand when an event (or a set of events) can be added to a configuration, together with a set of events modeling dependencies, which will play a less important role. We show that most of the notions of Event Structure presented in literature can be translated into this new kind of event structure, preserving the main notion, namely the one of configuration.","categories":"cs.LO","primary_cat":"cs.LO"},{"id":1910.10792,"authors":"Safwan Alfattani, Wael Jaafar, Halim Yanikomeroglu, Abbas Yongacoglu","title":"Multi-UAV Data Collection Framework for Wireless Sensor Networks","abstract":"In this paper, we propose a framework design for wireless sensor networks based on multiple unmanned aerial vehicles (UAVs). Specifically, we aim to minimize deployment and operational costs, with respect to budget and power constraints. To this end, we first optimize the number and locations of cluster heads (CHs) guaranteeing data collection from all sensors. Then, to minimize the data collection flight time, we optimize the number and trajectories of UAVs. Accordingly, we distinguish two trajectory approaches: 1) where a UAV hovers exactly above the visited CH; and 2) where a UAV hovers within a range of the CH. The results of this include guidelines for data collection design. The characteristics of sensor nodes' K-means clustering are then discussed. Next, we illustrate the performance of optimal and heuristic solutions for trajectory planning. The genetic algorithm is shown to be near-optimal with only $3.5\\%$ degradation. The impacts of the trajectory approach, environment, and UAVs' altitude are investigated. Finally, fairness of UAVs trajectories is discussed.","categories":"eess.SP cs.NI","primary_cat":"eess.SP"},{"id":1910.10652,"authors":"Fei Xu, Yingtao Zhang, Min Xian, H. D. Cheng, Boyu Zhang, Jianrui\n  Ding, Chunping Ning, Ying Wang","title":"Breast Anatomy Enriched Tumor Saliency Estimation","abstract":"Breast cancer investigation is of great significance, and developing tumor detection methodologies is a critical need. However, it is a challenging task for breast ultrasound due to the complicated breast structure and poor quality of the images. In this paper, we propose a novel tumor saliency estimation model guided by enriched breast anatomy knowledge to localize the tumor. Firstly, the breast anatomy layers are generated by a deep neural network. Then we refine the layers by integrating a non-semantic breast anatomy model to solve the problems of incomplete mammary layers. Meanwhile, a new background map generation method weighted by the semantic probability and spatial distance is proposed to improve the performance. The experiment demonstrates that the proposed method with the new background map outperforms four state-of-the-art TSE models with increasing 10% of F_meansure on the BUS public dataset.","categories":"cs.CV","primary_cat":"cs.CV"},{"id":1910.05273,"authors":"Cailin O'Connor","title":"The Natural Selection of Conservative Science","abstract":"Social epistemologists have argued that high risk, high reward science has an important role to play in scientific communities. Recently, though, it has also been argued that various scientific fields seem to be trending towards conservatism -- the increasing production of what Kuhn (1970) would have called `normal science'. This paper will explore a possible explanation for this sort of trend: that the process by which scientific research groups form, grow, and dissolve might be inherently hostile to high risk science. In particular, I employ a paradigm developed by Smaldino and McElreath (2016) that treats a scientific community as a population undergoing selection. As will become clear, perhaps counter-intuitively this sort of process in some ways promotes high risk, high reward science. But, as I will point out, high risk high reward science is, in general, the sort of thing that is hard to repeat. While more conservative scientists will be able to train students capable of continuing their successful projects, and so create thriving lineages, successful risky science may not be the sort of thing one can easily pass on. In such cases, the structure of scientific communities selects against high risk, high rewards projects. More generally, this paper makes clear that there are at least two processes to consider in thinking about how incentives shape scientific communities -- the process by which individual scientists make choices about their careers and research, and the selective process governing the formation of new research groups.","categories":"cs.DL physics.soc-ph","primary_cat":"cs.DL"}]