id,title,abstract,categories
1801.00779,Machine Learning for Building Energy and Indoor Environment: A Perspective,"Machine learning is a promising technique for many practical applications. In this perspective, we illustrate the development and application for machine learning. It is indicated that the theories and applications of machine learning method in the field of energy conservation and indoor environment are not mature, due to the difficulty of the determination for model structure with better prediction. In order to significantly contribute to the problems, we utilize the ANN model to predict the indoor culturable fungi concentration, which achieves the better accuracy and convenience. The proposal of hybrid method is further expand the application fields of machine learning method. Further, ANN model based on HTS was successfully applied for the optimization of building energy system. We hope that this novel method could capture more attention from investigators via our introduction and perspective, due to its potential development with accuracy and reliability. However, its feasibility in other fields needs to be promoted further.",cs.CY cs.LG
1908.02322,DpgMedia2019: A Dutch News Dataset for Partisanship Detection,"We present a new Dutch news dataset with labeled partisanship. The dataset contains more than 100K articles that are labeled on the publisher level and 776 articles that were crowdsourced using an internal survey platform and labeled on the article level. In this paper, we document our original motivation, the collection and annotation process, limitations, and applications.",cs.CL
1003.3767,Multi-Agent Simulation and Management Practices,"Intelligent agents offer a new and exciting way of understanding the world of work. Agent-Based Simulation (ABS), one way of using intelligent agents, carries great potential for progressing our understanding of management practices and how they link to retail performance. We have developed simulation models based on research by a multi-disciplinary team of economists, work psychologists and computer scientists. We will discuss our experiences of implementing these concepts working with a well-known retail department store. There is no doubt that management practices are linked to the performance of an organisation (Reynolds et al., 2005; Wall & Wood, 2005). Best practices have been developed, but when it comes down to the actual application of these guidelines considerable ambiguity remains regarding their effectiveness within particular contexts (Siebers et al., forthcoming a). Most Operational Research (OR) methods can only be used as analysis tools once management practices have been implemented. Often they are not very useful for giving answers to speculative 'what-if' questions, particularly when one is interested in the development of the system over time rather than just the state of the system at a certain point in time. Simulation can be used to analyse the operation of dynamic and stochastic systems. ABS is particularly useful when complex interactions between system entities exist, such as autonomous decision making or negotiation. In an ABS model the researcher explicitly describes the decision process of simulated actors at the micro level. Structures emerge at the macro level as a result of the actions of the agents and their interactions with other agents and the environment. 3 We will show how ABS experiments can deal with testing and optimising management practices such as training, empowerment or teamwork. Hence, questions such as ""will staff setting their own break times improve performance?"" can be investigated.",cs.AI cs.CE cs.MA
1811.08039,Fenchel Lifted Networks: A Lagrange Relaxation of Neural Network Training,"Despite the recent successes of deep neural networks, the corresponding training problem remains highly non-convex and difficult to optimize. Classes of models have been proposed that introduce greater structure to the objective function at the cost of lifting the dimension of the problem. However, these lifted methods sometimes perform poorly compared to traditional neural networks. In this paper, we introduce a new class of lifted models, Fenchel lifted networks, that enjoy the same benefits as previous lifted models, without suffering a degradation in performance over classical networks. Our model represents activation functions as equivalent biconvex constraints and uses Lagrange Multipliers to arrive at a rigorous lower bound of the traditional neural network training problem. This model is efficiently trained using block-coordinate descent and is parallelizable across data points and/or layers. We compare our model against standard fully connected and convolutional networks and show that we are able to match or beat their performance.",cs.LG stat.ML
1708.02772,On Maximum Common Subgraph Problems in Series-Parallel Graphs,"The complexity of the maximum common connected subgraph problem in partial $k$-trees is still not fully understood. Polynomial-time solutions are known for degree-bounded outerplanar graphs, a subclass of the partial $2$-trees. On the other hand, the problem is known to be ${\bf NP}$-hard in vertex-labeled partial $11$-trees of bounded degree. We consider series-parallel graphs, i.e., partial $2$-trees. We show that the problem remains ${\bf NP}$-hard in biconnected series-parallel graphs with all but one vertex of degree $3$ or less. A positive complexity result is presented for a related problem of high practical relevance which asks for a maximum common connected subgraph that preserves blocks and bridges of the input graphs. We present a polynomial time algorithm for this problem in series-parallel graphs, which utilizes a combination of BC- and SP-tree data structures to decompose both graphs.",cs.DS cs.CC
1012.1636,Fundamentals of Semantic Web Technologies in Medical Environments: a case in breast cancer risk estimation,"Risk estimation of developing breast cancer poses as the first prevention method for early diagnosis. Furthermore, data integration from different departments involved in the process plays a key role. In order to guarantee patient safety, the whole process should be orchestrated and monitored automatically. Support for the solution will be a linked data cloud, composed by all the departments that take part in the process, combined with rule engines.",cs.OH
1602.02215,Swivel: Improving Embeddings by Noticing What's Missing,"We present Submatrix-wise Vector Embedding Learner (Swivel), a method for generating low-dimensional feature embeddings from a feature co-occurrence matrix. Swivel performs approximate factorization of the point-wise mutual information matrix via stochastic gradient descent. It uses a piecewise loss with special handling for unobserved co-occurrences, and thus makes use of all the information in the matrix. While this requires computation proportional to the size of the entire matrix, we make use of vectorized multiplication to process thousands of rows and columns at once to compute millions of predicted values. Furthermore, we partition the matrix into shards in order to parallelize the computation across many nodes. This approach results in more accurate embeddings than can be achieved with methods that consider only observed co-occurrences, and can scale to much larger corpora than can be handled with sampling methods.",cs.CL
1902.03636,"Exploring Spatial, Temporal, and Logical Attacks on the Bitcoin Network","In this paper, we explore the partitioning attacks on the Bitcoin network, which is shown to exhibit spatial bias, and temporal and logical diversity. Through data-driven study we highlight: 1) the centralization of Bitcoin nodes across autonomous systems, indicating the possibility of BGP attacks, 2)the non-uniform consensus among nodes, that can be exploited to partition the network, and 3)the diversity in the Bitcoin software usage that can lead to privacy attacks. Atop the prior work, which focused on spatial partitioning, our work extends the analysis of the Bitcoin network to understand the temporal and logical effects on the robustness of the Bitcoin network.",cs.NI cs.CR
1512.00219,Placement and Assignment of Servers in Virtualized Radio Access Networks,"The virtualization of Radio Access Networks (RANs) has been proposed as one of the important use cases of Network Function Virtualization (NFV). In Virtualized Radio Access Networks (VRANs), some functions from a Base Station (BS), such as those which make up the Base Band Unit (BBU), may be implemented in a shared infrastructure located at either a data center or distributed in network nodes. For the latter option, one challenge is in deciding which subset of the available network nodes can be used to host the physical BBU servers (the placement problem), and then to which of the available physical BBUs each Remote Radio Head (RRH) should be assigned (the assignment problem). These two problems constitute what we refer to as the VRAN Placement and Assignment Problem (VRAN-PAP). In this paper, we start by formally defining the VRAN-PAP before formulating it as a Binary Integer Linear Program (BILP) whose objective is to minimize the server and front haul link setup costs as well as the latency between each RRH and its assigned BBU. Since the BILP could become computationally intractable, we also propose a greedy approximation for larger instances of the VRAN-PAP. We perform simulations to compare both algorithms in terms of solution quality as well as computation time under varying network sizes and setup budgets.",cs.NI
1802.10233,Apache Calcite: A Foundational Framework for Optimized Query Processing Over Heterogeneous Data Sources,"Apache Calcite is a foundational software framework that provides query processing, optimization, and query language support to many popular open-source data processing systems such as Apache Hive, Apache Storm, Apache Flink, Druid, and MapD. Calcite's architecture consists of a modular and extensible query optimizer with hundreds of built-in optimization rules, a query processor capable of processing a variety of query languages, an adapter architecture designed for extensibility, and support for heterogeneous data models and stores (relational, semi-structured, streaming, and geospatial). This flexible, embeddable, and extensible architecture is what makes Calcite an attractive choice for adoption in big-data frameworks. It is an active project that continues to introduce support for the new types of data sources, query languages, and approaches to query processing and optimization.",cs.DB
1204.0219,Improved Approximation for Orienting Mixed Graphs,"An instance of the maximum mixed graph orientation problem consists of a mixed graph and a collection of source-target vertex pairs. The objective is to orient the undirected edges of the graph so as to maximize the number of pairs that admit a directed source-target path. This problem has recently arisen in the study of biological networks, and it also has applications in communication networks. In this paper, we identify an interesting local-to-global orientation property. This property enables us to modify the best known algorithms for maximum mixed graph orientation and some of its special structured instances, due to Elberfeld et al. (CPM '11), and obtain improved approximation ratios. We further proceed by developing an algorithm that achieves an even better approximation guarantee for the general setting of the problem. Finally, we study several well-motivated variants of this orientation problem.",cs.DS
1810.05471,Safe Grid Search with Optimal Complexity,"Popular machine learning estimators involve regularization parameters that can be challenging to tune, and standard strategies rely on grid search for this task. In this paper, we revisit the techniques of approximating the regularization path up to predefined tolerance $\epsilon$ in a unified framework and show that its complexity is $O(1/\sqrt[d]{\epsilon})$ for uniformly convex loss of order $d \geq 2$ and $O(1/\sqrt{\epsilon})$ for Generalized Self-Concordant functions. This framework encompasses least-squares but also logistic regression, a case that as far as we know was not handled as precisely in previous works. We leverage our technique to provide refined bounds on the validation error as well as a practical algorithm for hyperparameter tuning. The latter has global convergence guarantee when targeting a prescribed accuracy on the validation set. Last but not least, our approach helps relieving the practitioner from the (often neglected) task of selecting a stopping criterion when optimizing over the training set: our method automatically calibrates this criterion based on the targeted accuracy on the validation set.",stat.ML cs.LG math.OC
1608.00751,Effective Capacity of Receive Antenna Selection MIMO-OSTBC Systems in Co-Channel Interference,"In this paper, delay constrained performance of a multiple-input multiple-output (MIMO) communication system in a dense environment with co-channel interference is investigated. We apply orthogonal space-time block coding (OSTBC) at the transmitter, and for alleviating the high complexity and cost of the MIMO system, receive antenna selection (RAS) scheme is employed in the downlink. Here, for simple and cheap mobile handsets, one antenna is chosen at the receiver in each utilization of the channel. Under these assumptions, a maximum constant arrival rate with the delay quality-of-service (QoS) guarantee in a wireless channel is extracted. We obtain a closed-form solution for the effective capacity of the MIMO-OSTBC channel with the RAS scheme in a quasi-static Rayleigh fading conditions and co-channel interference. After all, the numerical simulations are provided and verified the theoretical results.",cs.IT math.IT
1611.08219,The Off-Switch Game,"It is clear that one of the primary tools we can use to mitigate the potential risk from a misbehaving AI system is the ability to turn the system off. As the capabilities of AI systems improve, it is important to ensure that such systems do not adopt subgoals that prevent a human from switching them off. This is a challenge because many formulations of rational agents create strong incentives for self-preservation. This is not caused by a built-in instinct, but because a rational agent will maximize expected utility and cannot achieve whatever objective it has been given if it is dead. Our goal is to study the incentives an agent has to allow itself to be switched off. We analyze a simple game between a human H and a robot R, where H can press R's off switch but R can disable the off switch. A traditional agent takes its reward function for granted: we show that such agents have an incentive to disable the off switch, except in the special case where H is perfectly rational. Our key insight is that for R to want to preserve its off switch, it needs to be uncertain about the utility associated with the outcome, and to treat H's actions as important observations about that utility. (R also has no incentive to switch itself off in this setting.) We conclude that giving machines an appropriate level of uncertainty about their objectives leads to safer designs, and we argue that this setting is a useful generalization of the classical AI paradigm of rational agents.",cs.AI
1906.08479,High-temperature Expansions and Message Passing Algorithms,"Improved mean-field technics are a central theme of statistical physics methods applied to inference and learning. We revisit here some of these methods using high-temperature expansions for disordered systems initiated by Plefka, Georges and Yedidia. We derive the Gibbs free entropy and the subsequent self-consistent equations for a generic class of statistical models with correlated matrices and show in particular that many classical approximation schemes, such as adaptive TAP, Expectation-Consistency, or the approximations behind the Vector Approximate Message Passing algorithm all rely on the same assumptions, that are also at the heart of high-temperature expansions. We focus on the case of rotationally invariant random coupling matrices in the `high-dimensional' limit in which the number of samples and the dimension are both large, but with a fixed ratio. This encapsulates many widely studied models, such as Restricted Boltzmann Machines or Generalized Linear Models with correlated data matrices. In this general setting, we show that all the approximation schemes described before are equivalent, and we conjecture that they are exact in the thermodynamic limit in the replica symmetric phases. We achieve this conclusion by resummation of the infinite perturbation series, which generalizes a seminal result of Parisi and Potters. A rigorous derivation of this conjecture is an interesting mathematical challenge. On the way to these conclusions, we uncover several diagrammatical results in connection with free probability and random matrix theory, that are interesting independently of the rest of our work.",cond-mat.dis-nn cond-mat.stat-mech cs.IT math.IT math.PR
1804.10738,A Riemannian Corollary of Helly's Theorem,"We introduce a notion of halfspace for Hadamard manifolds that is natural in the context of convex optimization. For this notion of halfspace, we generalize a classic result of Gr\""unbaum, which itself is a corollary of Helly's theorem. Namely, given a probability distribution on the manifold, there is a point for which all halfspaces based at this point have at least $\frac{1}{n+1}$ of the mass. As an application, the gradient oracle complexity of convex optimization is polynomial in the parameters defining the problem.",math.MG cs.DS
1801.09486,On the Effective Energy Efficiency of Ultra-reliable Networks in the Finite Blocklength Regime,"Effective Capacity (EC) indicates the maximum communication rate subject to a certain delay constraint while effective energy efficiency (EEE) denotes the ratio between EC and power consumption. In this paper, we analyze the EEE of ultra-reliable networks operating in the finite blocklength regime. We obtain a closed form approximation for the EEE in Rayleigh block fading channels as a function of power, error probability, and delay. We show the optimum power allocation strategy for maximizing the EEE in finite blocklength transmission which reveals that Shannon's model underestimates the optimum power when compared to the exact finite blocklength model. Furthermore, we characterize the buffer constrained EEE maximization problem for different power consumption models. The results show that accounting for empty buffer probability (EBP) and extending the maximum delay tolerance jointly enhance the EC and EEE.",cs.IT math.IT
1803.06448,Frequency-Domain Decoupling for MIMO-GFDM Spatial Multiplexing,"Generalized frequency division multiplexing (GFDM) is considered a non-orthogonal waveform and known to encounter difficulties when using in the spatial multiplexing mode of multiple-input-multiple-output (MIMO) scenario. In this paper, a class of GFDM prototype filters, under which the GFDM system is free from inter-subcarrier interference, is investigated, enabling frequency-domain decoupling in the processing at the GFDM receiver. An efficient MIMO-GFDM detection method based on depth-first sphere decoding is then proposed with such class of filters. Numerical results confirm a significant reduction in complexity, especially when the number of subcarriers is large, compared with existing methods presented in recent years.",cs.IT math.IT
1805.00808,Formal Process Virtual Machine for Smart Contracts Verification,"This paper reports on the development and verification of a novel formal symbolic process virtual machine (FSPVM) for verifying the reliability and security of Ethereum smart contracts, denoted as FSPVM-E, completely in Coq proof assistant. It adopts execution-verification isomorphism (EVI), an extension of Curry-Howard isomorphism (CHI), as its fundamental theoretical framework. The current version of FSPVM-E is constructed on a general, extensible, and reusable formal memory (GERM) framework, an extensible and universal formal intermediate programming language Lolisa, which is a large subset of the Solidity programming language using generalized algebraic datatypes, and the corresponding formally verified interpreter of Lolisa, denoted as FEther. It supports the ERC20 standard and can automatically simultaneously symbolically execute the smart contract programs of Ethereum and verify their reliability and security properties using Hoare logic in Coq. In addition, this work, contributes to solving the problems of automation, inconsistency and reusability in higher-order logic theorem proving.",cs.PL
1904.07818,Maximizing Drift is Not Optimal for Solving OneMax,"It seems very intuitive that for the maximization of the OneMax problem $f(x):=\sum_{i=1}^n{x_i}$ the best that an elitist unary unbiased search algorithm can do is to store a best so far solution, and to modify it with the operator that yields the best possible expected progress in function value. This assumption has been implicitly used in several empirical works. In [Doerr, Doerr, Yang: GECCO 2016] it was formally proven that this approach is indeed almost optimal. In this work we prove that drift maximization is \emph{not} optimal. More precisely, we show that for most fitness levels $n/2<\ell/2 < 2n/3$ the optimal mutation strengths are larger than the drift-maximizing ones. This implies that the optimal RLS is more risk-affine than the variant maximizing the step-wise expected progress. We show similar results for the mutation rates of the classic (1+1) Evolutionary Algorithm (EA) and its resampling variant, the (1+1) EA$_{>0}$. As a result of independent interest we show that the optimal mutation strengths, unlike the drift-maximizing ones, can be even.",cs.NE
1704.02110,Non-linear maximum rank distance codes in the cyclic model for the field reduction of finite geometries,"In this paper we construct infinite families of non-linear maximum rank distance codes by using the setting of bilinear forms of a finite vector space. We also give a geometric description of such codes by using the cyclic model for the field reduction of finite geometries and we show that these families contain the non-linear maximum rank distance codes recently provided by Cossidente, Marino and Pavese.",cs.IT math.CO math.IT
1901.04119,Predicting the Mumble of Wireless Channel with Sequence-to-Sequence Models,"Accurate prediction of fading channel in the upcoming transmission frame is essential to realize adaptive transmission for transmitters, and receivers with the ability of channel prediction can also save some computations of channel estimation. However, due to the rapid channel variation and channel estimation error, reliable prediction is hard to realize. In this situation, an appropriate channel model should be selected, which can cover both the statistical model and small scale fading of channel, this reminds us the natural languages, which also have statistical word frequency and specific sentences. Accordingly, in this paper, we take wireless channel model as a language model, and the time-varying channel as talking in this language, while the realistic noisy estimated channel can be compared with mumbling. Furthermore, in order to utilize as much as possible the information a channel coefficient takes, we discard the conventional two features of absolute value and phase, replacing with hundreds of features which will be learned by our channel model, to do this, we use a vocabulary to map a complex channel coefficient into an ID, which is represented by a vector of real numbers. Recurrent neural networks technique is used as its good balance between memorization and generalization, moreover, we creatively introduce sequence-to-sequence (seq2seq) models in time series channel prediction, which can translates past channel into future channel. The results show that realistic channel prediction with superior performance relative to channel estimation is attainable.",eess.SP cs.IT math.IT
1902.08792,Identifying Malicious Web Domains Using Machine Learning Techniques with Online Credibility and Performance Data,"Malicious web domains represent a big threat to web users' privacy and security. With so much freely available data on the Internet about web domains' popularity and performance, this study investigated the performance of well-known machine learning techniques used in conjunction with this type of online data to identify malicious web domains. Two datasets consisting of malware and phishing domains were collected to build and evaluate the machine learning classifiers. Five single classifiers and four ensemble classifiers were applied to distinguish malicious domains from benign ones. In addition, a binary particle swarm optimisation (BPSO) based feature selection method was used to improve the performance of single classifiers. Experimental results show that, based on the web domains' popularity and performance data features, the examined machine learning techniques can accurately identify malicious domains in different ways. Furthermore, the BPSO-based feature selection procedure is shown to be an effective way to improve the performance of classifiers.",cs.CR cs.LG cs.NE
1107.2446,An EM Algorithm for Continuous-time Bivariate Markov Chains,"We study properties and parameter estimation of finite-state homogeneous continuous-time bivariate Markov chains. Only one of the two processes of the bivariate Markov chain is observable. The general form of the bivariate Markov chain studied here makes no assumptions on the structure of the generator of the chain, and hence, neither the underlying process nor the observable process is necessarily Markov. The bivariate Markov chain allows for simultaneous jumps of the underlying and observable processes. Furthermore, the inter-arrival time of observed events is phase-type. The bivariate Markov chain generalizes the batch Markovian arrival process as well as the Markov modulated Markov process. We develop an expectation-maximization (EM) procedure for estimating the generator of a bivariate Markov chain, and we demonstrate its performance. The procedure does not rely on any numerical integration or sampling scheme of the continuous-time bivariate Markov chain. The proposed EM algorithm is equally applicable to multivariate Markov chains.",stat.ME cs.PF
1411.1284,Kullback-Leibler divergence for interacting multiple model estimation with random matrices,"This paper studies the problem of interacting multiple model (IMM) estimation for jump Markov linear systems with unknown measurement noise covariance. The system state and the unknown covariance are jointly estimated in the framework of Bayesian estimation, where the unknown covariance is modeled as a random matrix according to an inverse-Wishart distribution. For the IMM estimation with random matrices, one difficulty encountered is the combination of a set of weighted inverse-Wishart distributions. Instead of using the moment matching approach, this difficulty is overcome by minimizing the weighted Kullback-Leibler divergence for inverse-Wishart distributions. It is shown that a closed form solution can be derived for the optimization problem and the resulting solution coincides with an inverse-Wishart distribution. Simulation results show that the proposed filter performs better than the previous work using the moment matching approach.",cs.SY
cs/0109111,Quality of service monitoring: Performance metrics across proprietary content domains,"We propose a quality of service (QoS) monitoring program for broadband access to measure the impact of proprietary network spaces. Our paper surveys other QoS policy initiatives, including those in the airline, and wireless and wireline telephone industries, to situate broadband in the context of other markets undergoing regulatory devolution. We illustrate how network architecture can create impediments to open communications, and how QoS monitoring can detect such effects. We present data from a field test of QoS-monitoring software now in development. We suggest QoS metrics to gauge whether information ""walled gardens"" represent a real threat for dividing the Internet into proprietary spaces. To demonstrate our proposal, we are placing our software on the computers of a sample of broadband subscribers. The software periodically conducts a battery of tests that assess the quality of connections from the subscriber's computer to various content sites. Any systematic differences in connection quality between affiliated and non-affiliated content sites would warrant research into the behavioral implications of those differences. QoS monitoring is timely because the potential for the Internet to break into a loose network of proprietary content domains appears stronger than ever. Recent court rulings and policy statements suggest a growing trend towards relaxed scrutiny of mergers and the easing or elimination of content ownership rules. This policy environment could lead to a market with a small number of large, vertically integrated network operators, each pushing its proprietary content on subscribers.",cs.CY
1203.3864,Matrix ALPS: Accelerated Low Rank and Sparse Matrix Reconstruction,"We propose Matrix ALPS for recovering a sparse plus low-rank decomposition of a matrix given its corrupted and incomplete linear measurements. Our approach is a first-order projected gradient method over non-convex sets, and it exploits a well-known memory-based acceleration technique. We theoretically characterize the convergence properties of Matrix ALPS using the stable embedding properties of the linear measurement operator. We then numerically illustrate that our algorithm outperforms the existing convex as well as non-convex state-of-the-art algorithms in computational efficiency without sacrificing stability.",cs.IT math.IT
1606.01148,Tripartite Unions,This note provides conditions under which the union of three well-founded binary relations is also well-founded.,cs.LO
1801.00840,High Performance Architecture for Flow-Table Lookup in SDN on FPGA,"We propose Range-based Ternary Search Tree (RTST), a tree-based approach for flow-table lookup in SDN network. RTST builds upon flow-tables in SDN switches to provide a fast lookup among flows. We present a parallel multi-pipeline architecture for implementing RTST that benefits from high throughput and low latency. The proposed RTST and architecture achieve a memory efficiency of 1 byte of memory for each byte of flow. We also present a set of techniques to support dynamic updates. Experimental results show that RTST can be used to improve the performance of flow-lookup. It achieves a throughput of 670 Million Packets Per Second (MPPS), for a 1 K 15-tuple flow-table, on a state-of-the-art FPGA.",cs.NI
1512.02363,On-Manifold Preintegration for Real-Time Visual-Inertial Odometry,"Current approaches for visual-inertial odometry (VIO) are able to attain highly accurate state estimation via nonlinear optimization. However, real-time optimization quickly becomes infeasible as the trajectory grows over time, this problem is further emphasized by the fact that inertial measurements come at high rate, hence leading to fast growth of the number of variables in the optimization. In this paper, we address this issue by preintegrating inertial measurements between selected keyframes into single relative motion constraints. Our first contribution is a \emph{preintegration theory} that properly addresses the manifold structure of the rotation group. We formally discuss the generative measurement model as well as the nature of the rotation noise and derive the expression for the \emph{maximum a posteriori} state estimator. Our theoretical development enables the computation of all necessary Jacobians for the optimization and a-posteriori bias correction in analytic form. The second contribution is to show that the preintegrated IMU model can be seamlessly integrated into a visual-inertial pipeline under the unifying framework of factor graphs. This enables the application of incremental-smoothing algorithms and the use of a \emph{structureless} model for visual measurements, which avoids optimizing over the 3D points, further accelerating the computation. We perform an extensive evaluation of our monocular \VIO pipeline on real and simulated datasets. The results confirm that our modelling effort leads to accurate state estimation in real-time, outperforming state-of-the-art approaches.",cs.RO
1509.02633,Uplink Pilot and Data Power Control for Single Cell Massive MIMO Systems with MRC,"This paper considers the jointly optimal pilot and data power allocation in single cell uplink massive MIMO systems. A closed form solution for the optimal length of the training interval is derived. Using the spectral efficiency (SE) as performance metric and setting a total energy budget per co- herence interval the power control is formulated as optimization problems for two different objective functions: the minimum SE among the users and the sum SE. The optimal power control policy is found for the case of maximizing the minimum SE by converting it to a geometric program (GP). Since maximizing the sum SE is an NP-hard problem, an efficient algorithm is developed for finding KKT (local maximum) points. Simulation results show the advantage of optimizing the power control over both pilot and data power, as compared to heuristic power control policies.",cs.IT math.IT math.OC
1009.0827,A Novel Watermarking Scheme for Detecting and Recovering Distortions in Database Tables,"In this paper a novel fragile watermarking scheme is proposed to detect, localize and recover malicious modifications in relational databases. In the proposed scheme, all tuples in the database are first securely divided into groups. Then watermarks are embedded and verified group-by-group independently. By using the embedded watermark, we are able to detect and localize the modification made to the database and even we recover the true data from the database modified locations. Our experimental results show that this scheme is so qualified; i.e. distortion detection and true data recovery both are performed successfully.",cs.DB
cs/0603026,The Snowblower Problem,"We introduce the snowblower problem (SBP), a new optimization problem that is closely related to milling problems and to some material-handling problems. The objective in the SBP is to compute a short tour for the snowblower to follow to remove all the snow from a domain (driveway, sidewalk, etc.). When a snowblower passes over each region along the tour, it displaces snow into a nearby region. The constraint is that if the snow is piled too high, then the snowblower cannot clear the pile. We give an algorithmic study of the SBP. We show that in general, the problem is NP-complete, and we present polynomial-time approximation algorithms for removing snow under various assumptions about the operation of the snowblower. Most commercially-available snowblowers allow the user to control the direction in which the snow is thrown. We differentiate between the cases in which the snow can be thrown in any direction, in any direction except backwards, and only to the right. For all cases, we give constant-factor approximation algorithms; the constants increase as the throw direction becomes more restricted. Our results are also applicable to robotic vacuuming (or lawnmowing) with bounded capacity dust bin and to some versions of material-handling problems, in which the goal is to rearrange cartons on the floor of a warehouse.",cs.DS cs.CC cs.RO
1905.04535,Multitask Deep Learning with Spectral Knowledge for Hyperspectral Image Classification,"In this letter, we propose a multitask deep learning method for classification of multiple hyperspectral data in a single training. Deep learning models have achieved promising results on hyperspectral image classification, but their performance highly rely on sufficient labeled samples, which are scarce on hyperspectral images. However, samples from multiple data sets might be sufficient to train one deep learning model, thereby improving its performance. To do so, we trained an identical feature extractor for all data, and the extracted features were fed into corresponding softmax classifiers. Spectral knowledge was introduced to ensure that the shared features were similar across domains. Four hyperspectral data sets were used in the experiments. We achieved higher classification accuracies on three data sets (Pavia University, Pavia Center, and Indian Pines) and competitive results on the Salinas Valley data compared with the baseline. Spectral knowledge was useful to prevent the deep network from overfitting when the data shared similar spectral response. The proposed method successfully utilized samples from multiple data sets to increase its performance.",cs.CV
1501.05286,Distributed mining of large scale remote sensing image archives on public computing infrastructures,"Earth Observation (EO) mining aims at supporting efficient access and exploration of petabyte-scale space- and airborne remote sensing archives that are currently expanding at rates of terabytes per day. A significant challenge is performing the analysis required by envisaged applications --- like for instance process mapping for environmental risk management --- in reasonable time. In this work, we address the problem of content-based image retrieval via example-based queries from EO data archives. In particular, we focus on the analysis of polarimetric SAR data, for which target decomposition theorems have proved fundamental in discovering patterns in data and characterize the ground scattering properties. To this end, we propose an interactive region-oriented content-based image mining system in which 1) unsupervised ingestion processes are distributed onto virtual machines in elastic, on-demand computing infrastructures 2) archive-scale content hierarchical indexing is implemented in terms of a ""big data"" analytics cluster-computing framework 3) query processing amounts to traversing the generated binary tree index, computing distances that correspond to descriptor-based similarity measures between image groups and a query image tile. We describe in depth both the strategies and the actual implementations for the ingestion and indexing components, and verify the approach by experiments carried out on the NASA/JPL UAVSAR full polarimetric data archive. We report the results of the tests performed on computer clusters by using a public Infrastructure-as-a-Service and evaluating the impact of cluster configuration on system performance. Results are promising for data mapping and information retrieval applications.",cs.DC
1501.04260,Disease spread over randomly switched large-scale networks,"In this paper we study disease spread over a randomly switched network, which is modeled by a stochastic switched differential equation based on the so called $N$-intertwined model for disease spread over static networks. Assuming that all the edges of the network are independently switched, we present sufficient conditions for the convergence of infection probability to zero. Though the stability theory for switched linear systems can naively derive a necessary and sufficient condition for the convergence, the condition cannot be used for large-scale networks because, for a network with $n$ agents, it requires computing the maximum real eigenvalue of a matrix of size exponential in $n$. On the other hand, our conditions that are based also on the spectral theory of random matrices can be checked by computing the maximum real eigenvalue of a matrix of size exactly $n$.",cs.SY cs.SI q-bio.PE
1503.00948,Hilbert-Post completeness for the state and the exception effects,"In this paper, we present a novel framework for studying the syntactic completeness of computational effects and we apply it to the exception effect. When applied to the states effect, our framework can be seen as a generalization of Pretnar's work on this subject. We first introduce a relative notion of Hilbert-Post completeness, well-suited to the composition of effects. Then we prove that the exception effect is relatively Hilbert-Post complete, as well as the ""core"" language which may be used for implementing it; these proofs have been formalized and checked with the proof assistant Coq.",cs.LO
1811.11374,A Deep Cascade Model for Multi-Document Reading Comprehension,"A fundamental trade-off between effectiveness and efficiency needs to be balanced when designing an online question answering system. Effectiveness comes from sophisticated functions such as extractive machine reading comprehension (MRC), while efficiency is obtained from improvements in preliminary retrieval components such as candidate document selection and paragraph ranking. Given the complexity of the real-world multi-document MRC scenario, it is difficult to jointly optimize both in an end-to-end system. To address this problem, we develop a novel deep cascade learning model, which progressively evolves from the document-level and paragraph-level ranking of candidate texts to more precise answer extraction with machine reading comprehension. Specifically, irrelevant documents and paragraphs are first filtered out with simple functions for efficiency consideration. Then we jointly train three modules on the remaining texts for better tracking the answer: the document extraction, the paragraph extraction and the answer extraction. Experiment results show that the proposed method outperforms the previous state-of-the-art methods on two large-scale multi-document benchmark datasets, i.e., TriviaQA and DuReader. In addition, our online system can stably serve typical scenarios with millions of daily requests in less than 50ms.",cs.CL
1811.08850,Generic Partition Refinement and Weighted Tree Automata,"Partition refinement is a method for minimizing automata and transition systems of various types. Recently, we have developed a partition refinement algorithm that is generic in the transition type of the given system and matches the run time of the best known algorithms for many concrete types of systems, e.g. deterministic automata as well as ordinary, weighted, and probabilistic (labelled) transition systems. Genericity is achieved by modelling transition types as functors on sets, and systems as coalgebras. In the present work, we refine the run time analysis of our algorithm to cover additional instances, notably weighted automata and, more generally, weighted tree automata. For weights in a cancellative monoid we match, and for non-cancellative monoids such as (the additive monoid of) the tropical semiring even substantially improve, the asymptotic run time of the best known algorithms. We have implemented our algorithm in a generic tool that is easily instantiated to concrete system types by implementing a simple refinement interface. Moreover, the algorithm and the tool are modular, and partition refiners for new types of systems are obtained easily by composing pre-implemented basic functors. Experiments show that even for complex system types, the tool is able to handle systems with millions of transitions.",cs.DS
1302.1859,The Relation Between Offset and Conchoid Constructions,"The one-sided offset surface Fd of a given surface F is, roughly speaking, obtained by shifting the tangent planes of F in direction of its oriented normal vector. The conchoid surface Gd of a given surface G is roughly speaking obtained by increasing the distance of G to a fixed reference point O by d. Whereas the offset operation is well known and implemented in most CAD-software systems, the conchoid operation is less known, although already mentioned by the ancient Greeks, and recently studied by some authors. These two operations are algebraic and create new objects from given input objects. There is a surprisingly simple relation between the offset and the conchoid operation. As derived there exists a rational bijective quadratic map which transforms a given surface F and its offset surfaces Fd to a surface G and its conchoidal surface Gd, and vice versa. Geometric properties of this map are studied and illustrated at hand of some complete examples. Furthermore rational universal parameterizations for offsets and conchoid surfaces are provided.",math.AG cs.CG
1701.03918,Marked Temporal Dynamics Modeling based on Recurrent Neural Network,"We are now witnessing the increasing availability of event stream data, i.e., a sequence of events with each event typically being denoted by the time it occurs and its mark information (e.g., event type). A fundamental problem is to model and predict such kind of marked temporal dynamics, i.e., when the next event will take place and what its mark will be. Existing methods either predict only the mark or the time of the next event, or predict both of them, yet separately. Indeed, in marked temporal dynamics, the time and the mark of the next event are highly dependent on each other, requiring a method that could simultaneously predict both of them. To tackle this problem, in this paper, we propose to model marked temporal dynamics by using a mark-specific intensity function to explicitly capture the dependency between the mark and the time of the next event. Extensive experiments on two datasets demonstrate that the proposed method outperforms state-of-the-art methods at predicting marked temporal dynamics.",cs.LG stat.ML
1603.02752,Best-of-K Bandits,"This paper studies the Best-of-K Bandit game: At each time the player chooses a subset S among all N-choose-K possible options and observes reward max(X(i) : i in S) where X is a random vector drawn from a joint distribution. The objective is to identify the subset that achieves the highest expected reward with high probability using as few queries as possible. We present distribution-dependent lower bounds based on a particular construction which force a learner to consider all N-choose-K subsets, and match naive extensions of known upper bounds in the bandit setting obtained by treating each subset as a separate arm. Nevertheless, we present evidence that exhaustive search may be avoided for certain, favorable distributions because the influence of high-order order correlations may be dominated by lower order statistics. Finally, we present an algorithm and analysis for independent arms, which mitigates the surprising non-trivial information occlusion that occurs due to only observing the max in the subset. This may inform strategies for more general dependent measures, and we complement these result with independent-arm lower bounds.",cs.LG stat.ML
1106.0967,Hashing Algorithms for Large-Scale Learning,"In this paper, we first demonstrate that b-bit minwise hashing, whose estimators are positive definite kernels, can be naturally integrated with learning algorithms such as SVM and logistic regression. We adopt a simple scheme to transform the nonlinear (resemblance) kernel into linear (inner product) kernel; and hence large-scale problems can be solved extremely efficiently. Our method provides a simple effective solution to large-scale learning in massive and extremely high-dimensional datasets, especially when data do not fit in memory. We then compare b-bit minwise hashing with the Vowpal Wabbit (VW) algorithm (which is related the Count-Min (CM) sketch). Interestingly, VW has the same variances as random projections. Our theoretical and empirical comparisons illustrate that usually $b$-bit minwise hashing is significantly more accurate (at the same storage) than VW (and random projections) in binary data. Furthermore, $b$-bit minwise hashing can be combined with VW to achieve further improvements in terms of training speed, especially when $b$ is large.",stat.ML cs.LG
1706.06333,Fast Load Balancing Approach for Growing Clusters by Bioinformatics,"This paper presents Fast load balancing technique inspired by Bioinformatics is a special case to assign a particular patient with a specialist physician cluster at real time. The work is considered soft presentation of the Gaussian mixture model based on the extracted features supplied by patients. Based on the likelihood ratio test, the patient is assigned to a specialist physician cluster. The presented algorithms efficiently handle any size and any numbers of incoming patient requests and rapidly placed them to the specialist physician cluster. Hence it smoothly balances the traffic load of patients even at a hazard situation in the case of natural calamities. The simulation results are presented with variable size of specialist physician clusters that well address the issue for randomly growing patient size.",cs.DC
1711.00005,Performance Optimization and Parallelization of a Parabolic Equation Solver in Computational Ocean Acoustics on Modern Many-core Computer,"As one of open-source codes widely used in computational ocean acoustics, FOR3D can provide a very good estimate for underwater acoustic propagation. In this paper, we propose a performance optimization and parallelization to speed up the running of FOR3D. We utilized a variety of methods to enhance the entire performance, such as using a multi-threaded programming model to exploit the potential capability of the many-core node of high-performance computing (HPC) system, tuning compile options, using efficient tuned mathematical library and utilizing vectorization optimization instruction. In addition, we extended the application from single-frequency calculation to multi-frequency calculation successfully by using OpenMP+MPI hybrid programming techniques on the mainstream HPC platform. A detailed performance evaluation was performed and the results showed that the proposed parallelization obtained good accelerated effect of 25.77X when testing a typical three-dimensional medium-sized case on Tianhe-2 supercomputer. It also showed that the tuned parallel version has a weak-scalability. The speed of calculation of underwater sound field can be greatly improved by the strategy mentioned in this paper. The method used in this paper is not only applicable to other similar computing models in computational ocean acoustics but also a guideline of performance enhancement for scientific and engineering application running on modern many-core-computing platform.",cs.MS cs.CE cs.PF
1403.1091,Signal Estimation from Nonuniform Samples with RMS Error Bound -- Application to OFDM Channel Estimation,"We present a channel spectral estimator for OFDM signals containing pilot carriers, assuming a known delay spread or a bound on this parameter. The estimator is based on modeling the channel's spectrum as a band-limited function, instead of as the discrete Fourier transform of a tapped delay line (TDL). Its main advantage is its immunity to the truncation mismatch in usual TDL models (Gibbs phenomenon). In order to assess the estimator, we compare it with the well-known TDL maximum likelihood (ML) estimator in terms of root-mean-square (RMS) error. The main result is that the proposed estimator improves on the ML estimator significantly, whenever the average spectral sampling rate is above the channel's delay spread. The improvement increases with the spectral oversampling ratio.",cs.IT math.IT
1710.05267,MR fingerprinting Deep RecOnstruction NEtwork (DRONE),"PURPOSE: Demonstrate a novel fast method for reconstruction of multi-dimensional MR Fingerprinting (MRF) data using Deep Learning methods. METHODS: A neural network (NN) is defined using the TensorFlow framework and trained on simulated MRF data computed using the Bloch equations. The accuracy of the NN reconstruction of noisy data is compared to conventional MRF template matching as a function of training data size, and quantified in a both simulated numerical brain phantom data and acquired data from the ISMRM/NIST phantom. The utility of the method is demonstrated in a healthy subject in vivo at 1.5 T. RESULTS: Network training required 10 minutes and once trained, data reconstruction required approximately 10 ms. Reconstruction of simulated brain data using the NN resulted in a root-mean-square error (RMSE) of 3.5 ms for T1 and 7.8 ms for T2. The RMSE for the NN trained on sparse dictionaries was approximately 6 fold lower for T1 and 2 fold lower for T2 than conventional MRF dot-product dictionary matching on the same dictionaries. Phantom measurements yielded good agreement (R2=0.99) between the T1 and T2 estimated by the NN and reference values from the ISMRM/NIST phantom. CONCLUSION: Reconstruction of MRF data with a NN is accurate, 300 fold faster and more robust to noise and undersampling than conventional MRF dictionary matching.",cs.CV
1906.03323,Empirical Likelihood for Contextual Bandits,"We apply empirical likelihood techniques to contextual bandit policy value estimation, confidence intervals, and learning. We propose a tighter estimator for off-policy evaluation with improved statistical performance over previous proposals. Coupled with this estimator is a confidence interval which also improves over previous proposals. We then harness these to improve learning from contextual bandit data. Each of these is empirically evaluated to show good performance against strong baselines in finite sample regimes.",cs.LG stat.ML
1803.00031,A Feature Clustering Approach Based on Histogram of Oriented Optical Flow and Superpixels,"Visual feature clustering is one of the cost-effective approaches to segment objects in videos. However, the assumptions made for developing the existing algorithms prevent them from being used in situations like segmenting an unknown number of static and moving objects under heavy camera movements. This paper addresses the problem by introducing a clustering approach based on superpixels and short-term Histogram of Oriented Optical Flow (HOOF). Salient Dither Pattern Feature (SDPF) is used as the visual feature to track the flow and Simple Linear Iterative Clustering (SLIC) is used for obtaining the superpixels. This new clustering approach is based on merging superpixels by comparing short term local HOOF and a color cue to form high-level semantic segments. The new approach was compared with one of the latest feature clustering approaches based on K-Means in eight-dimensional space and the results revealed that the new approach is better by means of consistency, completeness, and spatial accuracy. Further, the new approach completely solved the problem of not knowing the number of objects in a scene.",cs.CV
1107.2451,Surface tension of multi-phase flow with multiple junctions governed by the variational principle,"We explore a computational model of an incompressible fluid with a multi-phase field in three-dimensional Euclidean space. By investigating an incompressible fluid with a two-phase field geometrically, we reformulate the expression of the surface tension for the two-phase field found by Lafaurie, Nardone, Scardovelli, Zaleski and Zanetti (J. Comp. Phys. \vol{113} \yr{1994} \pages{134-147}) as a variational problem related to an infinite dimensional Lie group, the volume-preserving diffeomorphism. The variational principle to the action integral with the surface energy reproduces their Euler equation of the two-phase field with the surface tension. Since the surface energy of multiple interfaces even with singularities is not difficult to be evaluated in general and the variational formulation works for every action integral, the new formulation enables us to extend their expression to that of a multi-phase ($N$-phase, $N\ge2$) flow and to obtain a novel Euler equation with the surface tension of the multi-phase field. The obtained Euler equation governs the equation of motion of the multi-phase field with different surface tension coefficients without any difficulties for the singularities at multiple junctions. In other words, we unify the theory of multi-phase fields which express low dimensional interface geometry and the theory of the incompressible fluid dynamics on the infinite dimensional geometry as a variational problem. We apply the equation to the contact angle problems at triple junctions. We computed the fluid dynamics for a two-phase field with a wall numerically and show the numerical computational results that for given surface tension coefficients, the contact angles are generated by the surface tension as results of balances of the kinematic energy and the surface energy.",cs.NA math-ph math.DG math.MP math.NA physics.comp-ph physics.flu-dyn
1112.3714,Nonnegative Matrix Factorization for Semi-supervised Dimensionality Reduction,"We show how to incorporate information from labeled examples into nonnegative matrix factorization (NMF), a popular unsupervised learning algorithm for dimensionality reduction. In addition to mapping the data into a space of lower dimensionality, our approach aims to preserve the nonnegative components of the data that are important for classification. We identify these components from the support vectors of large-margin classifiers and derive iterative updates to preserve them in a semi-supervised version of NMF. These updates have a simple multiplicative form like their unsupervised counterparts; they are also guaranteed at each iteration to decrease their loss function---a weighted sum of I-divergences that captures the trade-off between unsupervised and supervised learning. We evaluate these updates for dimensionality reduction when they are used as a precursor to linear classification. In this role, we find that they yield much better performance than their unsupervised counterparts. We also find one unexpected benefit of the low dimensional representations discovered by our approach: often they yield more accurate classifiers than both ordinary and transductive SVMs trained in the original input space.",cs.LG
1508.04977,nanopub-java: A Java Library for Nanopublications,"The concept of nanopublications was first proposed about six years ago, but it lacked openly available implementations. The library presented here is the first one that has become an official implementation of the nanopublication community. Its core features are stable, but it also contains unofficial and experimental extensions: for publishing to a decentralized server network, for defining sets of nanopublications with indexes, for informal assertions, and for digitally signing nanopublications. Most of the features of the library can also be accessed via an online validator interface.",cs.DL
1004.2226,"Adiabatic Quantum Algorithms for the NP-Complete Maximum-Weight Independent Set, Exact Cover and 3SAT Problems","The problem Hamiltonian of the adiabatic quantum algorithm for the maximum-weight independent set problem (MIS) that is based on the reduction to the Ising problem (as described in [Choi08]) has flexible parameters. We show that by choosing the parameters appropriately in the problem Hamiltonian (without changing the problem to be solved) for MIS on CK graphs, we can prevent the first order quantum phase transition and significantly change the minimum spectral gap. We raise the basic question about what the appropriate formulation of adiabatic running time should be. We also describe adiabatic quantum algorithms for Exact Cover and 3SAT in which the problem Hamiltonians are based on the reduction to MIS. We point out that the argument in Altshuler et al.(arXiv:0908.2782 [quant-ph]) that their adiabatic quantum algorithm failed with high probability for randomly generated instances of Exact Cover does not carry over to this new algorithm.",quant-ph cs.CC
1711.06729,Phonological (un)certainty weights lexical activation,"Spoken word recognition involves at least two basic computations. First is matching acoustic input to phonological categories (e.g. /b/, /p/, /d/). Second is activating words consistent with those phonological categories. Here we test the hypothesis that the listener's probability distribution over lexical items is weighted by the outcome of both computations: uncertainty about phonological discretisation and the frequency of the selected word(s). To test this, we record neural responses in auditory cortex using magnetoencephalography, and model this activity as a function of the size and relative activation of lexical candidates. Our findings indicate that towards the beginning of a word, the processing system indeed weights lexical candidates by both phonological certainty and lexical frequency; however, later into the word, activation is weighted by frequency alone.",cs.CL
1703.06043,Pattern representation and recognition with accelerated analog neuromorphic systems,"Despite being originally inspired by the central nervous system, artificial neural networks have diverged from their biological archetypes as they have been remodeled to fit particular tasks. In this paper, we review several possibilites to reverse map these architectures to biologically more realistic spiking networks with the aim of emulating them on fast, low-power neuromorphic hardware. Since many of these devices employ analog components, which cannot be perfectly controlled, finding ways to compensate for the resulting effects represents a key challenge. Here, we discuss three different strategies to address this problem: the addition of auxiliary network components for stabilizing activity, the utilization of inherently robust architectures and a training method for hardware-emulated networks that functions without perfect knowledge of the system's dynamics and parameters. For all three scenarios, we corroborate our theoretical considerations with experimental results on accelerated analog neuromorphic platforms.",q-bio.NC cs.NE stat.ML
1512.05185,Power System Differential-Algebraic Equations,This document presents an introduction of two commonly used power system differential algebraic equations (DAEs) for studying power system dynamics like electromechanical oscillation and angle stability: the second-order classical model and the fourth-order detailed generator model. An example is provided on the IEEE 9-bus system.,cs.SY
1706.01487,Visual attention models for scene text recognition,"In this paper we propose an approach to lexicon-free recognition of text in scene images. Our approach relies on a LSTM-based soft visual attention model learned from convolutional features. A set of feature vectors are derived from an intermediate convolutional layer corresponding to different areas of the image. This permits encoding of spatial information into the image representation. In this way, the framework is able to learn how to selectively focus on different parts of the image. At every time step the recognizer emits one character using a weighted combination of the convolutional feature vectors according to the learned attention model. Training can be done end-to-end using only word level annotations. In addition, we show that modifying the beam search algorithm by integrating an explicit language model leads to significantly better recognition results. We validate the performance of our approach on standard SVT and ICDAR'03 scene text datasets, showing state-of-the-art performance in unconstrained text recognition.",cs.CV
1302.2224,Computer-Aided Derivation of Multi-scale Models: A Rewriting Framework,"We introduce a framework for computer-aided derivation of multi-scale models. It relies on a combination of an asymptotic method used in the field of partial differential equations with term rewriting techniques coming from computer science. In our approach, a multi-scale model derivation is characterized by the features taken into account in the asymptotic analysis. Its formulation consists in a derivation of a reference model associated to an elementary nominal model, and in a set of transformations to apply to this proof until it takes into account the wanted features. In addition to the reference model proof, the framework includes first order rewriting principles designed for asymptotic model derivations, and second order rewriting principles dedicated to transformations of model derivations. We apply the method to generate a family of homogenized models for second order elliptic equations with periodic coefficients that could be posed in multi-dimensional domains, with possibly multi-domains and/or thin domains.",cs.SC
1409.7316,An Analysis of Publication Venues for Automatic Differentiation Research,"We present the results of our analysis of publication venues for papers on automatic differentiation (AD), covering academic journals and conference proceedings. Our data are collected from the AD publications database maintained by the autodiff.org community website. The database is purpose-built for the AD field and is expanding via submissions by AD researchers. Therefore, it provides a relatively noise-free list of publications relating to the field. However, it does include noise in the form of variant spellings of journal and conference names. We handle this by manually correcting and merging these variants under the official names of corresponding venues. We also share the raw data we get after these corrections.",cs.DL cs.MS
1505.07310,Use of Laplacian Projection Technique for Summarizing Likert Scale Annotations,"Summarizing Likert scale ratings from human annotators is an important step for collecting human judgments. In this project we study a novel, graph theoretic method for this purpose. We also analyze a few interesting properties for this approach using real annotation datasets.",cs.HC
1402.0580,On the Computation of Fully Proportional Representation,"We investigate two systems of fully proportional representation suggested by Chamberlin Courant and Monroe. Both systems assign a representative to each voter so that the ""sum of misrepresentations"" is minimized. The winner determination problem for both systems is known to be NP-hard, hence this work aims at investigating whether there are variants of the proposed rules and/or specific electorates for which these problems can be solved efficiently. As a variation of these rules, instead of minimizing the sum of misrepresentations, we considered minimizing the maximal misrepresentation introducing effectively two new rules. In the general case these ""minimax"" versions of classical rules appeared to be still NP-hard. We investigated the parameterized complexity of winner determination of the two classical and two new rules with respect to several parameters. Here we have a mixture of positive and negative results: e.g., we proved fixed-parameter tractability for the parameter the number of candidates but fixed-parameter intractability for the number of winners. For single-peaked electorates our results are overwhelmingly positive: we provide polynomial-time algorithms for most of the considered problems. The only rule that remains NP-hard for single-peaked electorates is the classical Monroe rule.",cs.GT cs.MA
1409.2702,F-formation Detection: Individuating Free-standing Conversational Groups in Images,"Detection of groups of interacting people is a very interesting and useful task in many modern technologies, with application fields spanning from video-surveillance to social robotics. In this paper we first furnish a rigorous definition of group considering the background of the social sciences: this allows us to specify many kinds of group, so far neglected in the Computer Vision literature. On top of this taxonomy, we present a detailed state of the art on the group detection algorithms. Then, as a main contribution, we present a brand new method for the automatic detection of groups in still images, which is based on a graph-cuts framework for clustering individuals; in particular we are able to codify in a computational sense the sociological definition of F-formation, that is very useful to encode a group having only proxemic information: position and orientation of people. We call the proposed method Graph-Cuts for F-formation (GCFF). We show how GCFF definitely outperforms all the state of the art methods in terms of different accuracy measures (some of them are brand new), demonstrating also a strong robustness to noise and versatility in recognizing groups of various cardinality.",cs.CV
1903.07597,On the Capacity of Computation Broadcast,"The two-user computation broadcast problem is introduced as the setting where User $1$ wants message $W_1$ and has side-information $W_1'$, User $2$ wants message $W_2$ and has side-information $W_2'$, and $(W_1, W_1', W_2, W_2')$ may have arbitrary dependencies. The rate of a computation broadcast scheme is defined as the ratio $H(W_1,W_2)/H(S)$, where $S$ is the information broadcast to both users to simultaneously satisfy their demands. The supremum of achievable rates is called the capacity of computation broadcast $C_{{CB}}$. It is shown that $C_{{CB}}\leq H(W_1,W_2)/\left[H(W_1|W_1')+H(W_2|W_2')-\min\Big(I(W_1; W_2, W_2'|W_1'), I(W_2; W_1, W_1'|W_2')\Big)\right]$. For the linear computation broadcast problem, where $W_1, W_1', W_2, W_2'$ are comprised of arbitrary linear combinations of a basis set of independent symbols, the bound is shown to be tight. For non-linear computation broadcast, it is shown that this bound is not tight in general. Examples are provided to prove that different instances of computation broadcast that have the same entropic structure, i.e., the same entropy for all subsets of $\{W_1,W_1',W_2,W_2'\}$, can have different capacities. Thus, extra-entropic structure matters even for two-user computation broadcast. The significance of extra-entropic structure is further explored through a class of non-linear computation broadcast problems where the extremal values of capacity are shown to correspond to minimally and maximally structured problems within that class.",cs.IT math.IT
1808.09913,"Same Stats, Different Graphs (Graph Statistics and Why We Need Graph Drawings)","Data analysts commonly utilize statistics to summarize large datasets. While it is often sufficient to explore only the summary statistics of a dataset (e.g., min/mean/max), Anscombe's Quartet demonstrates how such statistics can be misleading. Graph mining has a similar problem in that graph statistics (e.g., density, connectivity, clustering coefficient) may not capture all of the critical properties of a given graph. To study the relationships between different graph properties and statistics, we examine all low-order (<= 10) non-isomorphic graphs and provide a simple visual analytics system to explore correlations across multiple graph properties. However, for graphs with more than ten nodes, generating the entire space of graphs becomes quickly intractable. We use different random graph generation methods to further look into the distribution of graph statistics for higher order graphs and investigate the impact of various sampling methodologies. We also describe a method for generating many graphs that are identical over a number of graph properties and statistics yet are clearly different and identifiably distinct.",cs.CG
1311.5830,Dictionary-Learning-Based Reconstruction Method for Electron Tomography,"Electron tomography usually suffers from so called missing wedge artifacts caused by limited tilt angle range. An equally sloped tomography (EST) acquisition scheme (which should be called the linogram sampling scheme) was recently applied to achieve 2.4-angstrom resolution. On the other hand, a compressive sensing-inspired reconstruction algorithm, known as adaptive dictionary based statistical iterative reconstruction (ADSIR), has been reported for x-ray computed tomography. In this paper, we evaluate the EST, ADSIR and an ordered-subset simultaneous algebraic reconstruction technique (OS-SART), and compare the ES and equally angled (EA) data acquisition modes. Our results show that OS-SART is comparable to EST, and the ADSIR outperforms EST and OS-SART. Furthermore, the equally sloped projection data acquisition mode has no advantage over the conventional equally angled mode in the context.",cs.CV physics.med-ph
1810.07159,Packaging and Sharing Machine Learning Models via the Acumos AI Open Platform,"Applying Machine Learning (ML) to business applications for automation usually faces difficulties when integrating diverse ML dependencies and services, mainly because of the lack of a common ML framework. In most cases, the ML models are developed for applications which are targeted for specific business domain use cases, leading to duplicated effort, and making reuse impossible. This paper presents Acumos, an open platform capable of packaging ML models into portable containerized microservices which can be easily shared via the platform's catalog, and can be integrated into various business applications. We present a case study of packaging sentiment analysis and classification ML models via the Acumos platform, permitting easy sharing with others. We demonstrate that the Acumos platform reduces the technical burden on application developers when applying machine learning models to their business applications. Furthermore, the platform allows the reuse of readily available ML microservices in various business domains.",cs.AI cs.SE
cs/0609113,Algebraic recognizability of regular tree languages,"We propose a new algebraic framework to discuss and classify recognizable tree languages, and to characterize interesting classes of such languages. Our algebraic tool, called preclones, encompasses the classical notion of syntactic Sigma-algebra or minimal tree automaton, but adds new expressivity to it. The main result in this paper is a variety theorem \`{a} la Eilenberg, but we also discuss important examples of logically defined classes of recognizable tree languages, whose characterization and decidability was established in recent papers (by Benedikt and S\'{e}goufin, and by Bojanczyk and Walukiewicz) and can be naturally formulated in terms of pseudovarieties of preclones. Finally, this paper constitutes the foundation for another paper by the same authors, where first-order definable tree languages receive an algebraic characterization.",cs.DM
1903.10837,Exploiting Computation Replication for Mobile Edge Computing: A Fundamental Computation-Communication Tradeoff Study,"Existing works on task offloading in mobile edge computing (MEC) networks often assume a task be executed once at a single edge node (EN). Downloading the computed result from the EN back to the mobile user may suffer long delay if the downlink channel experiences strong interference or deep fading. This paper exploits the idea of computation replication in MEC networks to speed up the downloading phase. Computation replication allows each user to offload its task to multiple ENs for repetitive execution so as to create multiple copies of the computed result at different ENs which can then enable transmission cooperation and hence reduce the communication latency for result downloading. Yet, computation replication may also increase the communication latency for task uploading, despite the obvious increase in computation load. The main contribution of this work is to characterize asymptotically an order-optimal upload-download communication latency pair for a given computation load in a multi-user multi-server MEC network. Analysis shows when the computation load increases within a certain range, the downloading time can decrease in an inversely proportional way if it is binary offloading or decrease linearly if it is partial offloading, both at the expense of increasing the uploading time linearly.",cs.IT math.IT
1610.07276,Intrusion Alert Prediction Using a Hidden Markov Model,"Intrusion detection is only a starting step in securing IT infrastructure. Prediction of intrusions is the next step to provide an active defense against incoming attacks. Current intrusion prediction methods focus mainly on prediction of either intrusion type or intrusion category and do not use or provide contextual information such as source and target IP address. In addition most of them are dependant on domain knowledge and specific scenario knowledge. The proposed algorithm employs a bag-of-words model together with a hidden Markov model which not depend on specific domain knowledge. Since this algorithm depends on a training process it is adaptable to different conditions. A key advantage of the proposed algorithm is the inclusion of contextual data such as source IP address, destination IP range, alert type and alert category in its prediction, which is crucial for an eventual response. Experiments conducted using a public data set generated over 2500 alert predictions and achieved accuracy of 81% and 77% for single step and five step predictions respectively for prediction of the next alert cluster. It also achieved an accuracy of prediction of 95% and 92% for single step and five step predictions respectively for prediction of the next alert category. The proposed methods achieved a prediction accuracy improvement of 5% for alert category over existing variable length Markov chain intrusion prediction methods, while providing more information for a possible defense.",cs.CR
1809.01170,"""This is why we play"": Characterizing Online Fan Communities of the NBA Teams","Professional sports constitute an important part of people's modern life. People spend substantial amounts of time and money supporting their favorite players and teams, and sometimes even riot after games. However, how team performance affects fan behavior remains understudied at a large scale. As almost every notable professional team has its own online fan community, these communities provide great opportunities for investigating this research question. In this work, we provide the first large-scale characterization of online fan communities of professional sports teams. Since user behavior in these online fan communities is inherently connected to game events and team performance, we construct a unique dataset that combines 1.5M posts and 43M comments in NBA-related communities on Reddit with statistics that document team performance in the NBA. We analyze the impact of team performance on fan behavior both at the game level and the season level. First, we study how team performance in a game relates to user activity during that game. We find that surprise plays an important role: the fans of the top teams are more active when their teams lose and so are the fans of the bottom teams in an unexpected win. Second, we study fan behavior over consecutive seasons and show that strong team performance is associated with fans of low loyalty, likely due to ""bandwagon fans."" Fans of the bottom teams tend to discuss their team's future such as young talents in the roster, which may help them stay optimistic during adversity. Our results not only contribute to understanding the interplay between online sports communities and offline context but also provide significant insights into sports management.",cs.SI
1411.5928,"Learning to Generate Chairs, Tables and Cars with Convolutional Networks","We train generative 'up-convolutional' neural networks which are able to generate images of objects given object style, viewpoint, and color. We train the networks on rendered 3D models of chairs, tables, and cars. Our experiments show that the networks do not merely learn all images by heart, but rather find a meaningful representation of 3D models allowing them to assess the similarity of different models, interpolate between given views to generate the missing ones, extrapolate views, and invent new objects not present in the training set by recombining training instances, or even two different object classes. Moreover, we show that such generative networks can be used to find correspondences between different objects from the dataset, outperforming existing approaches on this task.",cs.CV cs.LG cs.NE
1105.5951,Performance of Short-Commit in Extreme Database Environment,Atomic commit protocols are used where data integrity is more important than data availability. Two-Phase commit (2PC) is a standard commit protocol for commercial database management systems. To reduce certain drawbacks in 2PC protocol people have suggested different variance of this protocol. Short-Commit protocol is developed with an objective to achieve low cost transaction commitment cost with non-blocking capability. In this paper we have briefly explained short-commit protocol executing pattern. Experimental analysis and results are presented to support the claim that short-commit can work efficiently in extreme database environment.,cs.DB
1611.07556,Cultivating Software Performance in Cloud Computing,"There exist multitudes of cloud performance metrics, including workload performance, application placement, software/hardware optimization, scalability, capacity, reliability, agility and so on. In this paper, we consider jointly optimizing the performance of the software applications in the cloud. The challenges lie in bringing a diversity of raw data into tidy data format, unifying performance data from multiple systems based on timestamps, and assessing the quality of the processed performance data. Even after verifying the quality of cloud performance data, additional challenges block optimizing cloud computing. In this paper, we identify the challenges of cloud computing from the perspectives of computing environment, data collection, performance analytics and production environment.",cs.PF cs.DC
1412.7272,Learning Non-deterministic Representations with Energy-based Ensembles,"The goal of a generative model is to capture the distribution underlying the data, typically through latent variables. After training, these variables are often used as a new representation, more effective than the original features in a variety of learning tasks. However, the representations constructed by contemporary generative models are usually point-wise deterministic mappings from the original feature space. Thus, even with representations robust to class-specific transformations, statistically driven models trained on them would not be able to generalize when the labeled data is scarce. Inspired by the stochasticity of the synaptic connections in the brain, we introduce Energy-based Stochastic Ensembles. These ensembles can learn non-deterministic representations, i.e., mappings from the feature space to a family of distributions in the latent space. These mappings are encoded in a distribution over a (possibly infinite) collection of models. By conditionally sampling models from the ensemble, we obtain multiple representations for every input example and effectively augment the data. We propose an algorithm similar to contrastive divergence for training restricted Boltzmann stochastic ensembles. Finally, we demonstrate the concept of the stochastic representations on a synthetic dataset as well as test them in the one-shot learning scenario on MNIST.",cs.LG cs.NE
1610.01795,Multiple Regularizations Deep Learning for Paddy Growth Stages Classification from LANDSAT-8,"This study uses remote sensing technology that can provide information about the condition of the earth's surface area, fast, and spatially. The study area was in Karawang District, lying in the Northern part of West Java-Indonesia. We address a paddy growth stages classification using LANDSAT 8 image data obtained from multi-sensor remote sensing image taken in October 2015 to August 2016. This study pursues a fast and accurate classification of paddy growth stages by employing multiple regularizations learning on some deep learning methods such as DNN (Deep Neural Networks) and 1-D CNN (1-D Convolutional Neural Networks). The used regularizations are Fast Dropout, Dropout, and Batch Normalization. To evaluate the effectiveness, we also compared our method with other machine learning methods such as (Logistic Regression, SVM, Random Forest, and XGBoost). The data used are seven bands of LANDSAT-8 spectral data samples that correspond to paddy growth stages data obtained from i-Sky (eye in the sky) Innovation system. The growth stages are determined based on paddy crop phenology profile from time series of LANDSAT-8 images. The classification results show that MLP using multiple regularization Dropout and Batch Normalization achieves the highest accuracy for this dataset.",cs.CV cs.NE
1509.04218,Collaborative Bibliographic System for Review/Survey Articles,"This paper proposes a Bibliographic system intends to exchange bibliographic information of survey/review articles by relying on Web service technology. It allows researchers and university students to interact with system via single service using platform-independent standard named Web service to add, search and retrieve bibliographic information of review articles in various science and technology fields and build-up a dedicated database for these articles in each science and technology field. Additionally, different implementation scenarios of the proposed system are presented and described, and rich features that offered by such system are studied and described. However, this paper explains the proposed system using computing area due to the existence of detailed taxonomy of this area, which allows defining the system, their functionalities and features provided. However, the proposed system is not only confined to computing area, it can support any other science and technology area without any need to modify this system.",cs.DL
1104.5643,On the algebraic numbers computable by some generalized Ehrenfest urns,"This article deals with some stochastic population protocols, motivated by theoretical aspects of distributed computing. We modelize the problem by a large urn of black and white balls from which at every time unit a fixed number of balls are drawn and their colors are changed according to the number of black balls among them. When the time and the number of balls both tend to infinity the proportion of black balls converges to an algebraic number. We prove that, surprisingly enough, not every algebraic number can be ""computed"" this way.",cs.DC
1905.00833,A globally exponentially stable position observer for interior permanent magnet synchronous motors,"The design of a position observer for the interior permanent magnet synchronous motor is a challenging problem that, in spite of many research efforts, remained open for a long time. In this paper we present the first globally exponentially convergent solution to it. As expected in all observer tasks, a persistency of excitation condition is imposed. Conditions on the operation of the motor, under which it is verified, are given. In particular, it is shown that at rotor standstill---when the system is not observable---it is possible to inject a probing signal to enforce the persistent excitation condition. {The high performance of the proposed observer, in standstill and high speed regions, is verified by extensive series of test-runs on an experimental setup.",cs.SY
1210.5946,Bipolar Proof Nets for MALL,"In this work we present a computation paradigm based on a concurrent and incremental construction of proof nets (de-sequentialized or graphical proofs) of the pure multiplicative and additive fragment of Linear Logic, a resources conscious refinement of Classical Logic. Moreover, we set a correspon- dence between this paradigm and those more pragmatic ones inspired to transactional or distributed systems. In particular we show that the construction of additive proof nets can be interpreted as a model for super-ACID (or co-operative) transactions over distributed transactional systems (typi- cally, multi-databases).",cs.LO
1906.11285,Re-ranking Based Diversification: A Unifying View,"We analyze different re-ranking algorithms for diversification and show that majority of them are based on maximizing submodular/modular functions from the class of parameterized concave/linear over modular functions. We study the optimality of such algorithms in terms of the `total curvature'. We also show that by adjusting the hyperparameter of the concave/linear composition to trade-off relevance and diversity, if any, one is in fact tuning the `total curvature' of the function for relevance-diversity trade-off.",cs.IR stat.ML
1309.4062,Resource Optimization in Device-to-Device Cellular Systems Using Time-Frequency Hopping,"We develop a flexible and accurate framework for device-to-device (D2D) communication in the context of a conventional cellular network, which allows for time-frequency resources to be either shared or orthogonally partitioned between the two networks. Using stochastic geometry, we provide accurate expressions for SINR distributions and average rates, under an assumption of interference randomization via time and/or frequency hopping, for both dedicated and shared spectrum approaches. We obtain analytical results in closed or semi-closed form in high SNR regime, that allow us to easily explore the impact of key parameters (e.g., the load and hopping probabilities) on the network performance. In particular, unlike other models, the expressions we obtain are tractable, i.e., they can be efficiently optimized without extensive simulation. Using these, we optimize the hopping probabilities for the D2D links, i.e., how often they should request a time or frequency slot. This can be viewed as an optimized lower bound to other more sophisticated scheduling schemes. We also investigate the optimal resource partitions between D2D and cellular networks when they use orthogonal resources.",cs.IT math.IT
1304.6709,Designing the W3C Open Annotation Data Model,"The Open Annotation Core Data Model specifies an interoperable framework for creating associations between related resources, called annotations, using a methodology that conforms to the Architecture of the World Wide Web. Open Annotations can easily be shared between platforms, with sufficient richness of expression to satisfy complex requirements while remaining simple enough to also allow for the most common use cases, such as attaching a piece of text to a single web resource. This paper presents the W3C Open Annotation Community Group specification and the rationale behind the scoping and technical decisions that were made. It also motivates interoperable Annotations via use cases, and provides a brief analysis of the advantages over previous specifications.",cs.DL
1607.00854,Lecture Notes on the ARV Algorithm for Sparsest Cut,"One of the landmarks in approximation algorithms is the $O(\sqrt{\log n})$-approximation algorithm for the Uniform Sparsest Cut problem by Arora, Rao and Vazirani from 2004. The algorithm is based on a semidefinite program that finds an embedding of the nodes respecting the triangle inequality. Their core argument shows that a random hyperplane approach will find two large sets of $\Theta(n)$ many nodes each that have a distance of $\Theta(1/\sqrt{\log n})$ to each other if measured in terms of $\|\cdot \|_2^2$. Here we give a detailed set of lecture notes describing the algorithm. For the proof of the Structure Theorem we use a cleaner argument based on expected maxima over $k$-neighborhoods that significantly simplifies the analysis.",cs.DS cs.CG
1703.00185,Massively parallel lattice-Boltzmann codes on large GPU clusters,"This paper describes a massively parallel code for a state-of-the art thermal lattice- Boltzmann method. Our code has been carefully optimized for performance on one GPU and to have a good scaling behavior extending to a large number of GPUs. Versions of this code have been already used for large-scale studies of convective turbulence. GPUs are becoming increasingly popular in HPC applications, as they are able to deliver higher performance than traditional processors. Writing efficient programs for large clusters is not an easy task as codes must adapt to increasingly parallel architectures, and the overheads of node-to-node communications must be properly handled. We describe the structure of our code, discussing several key design choices that were guided by theoretical models of performance and experimental benchmarks. We present an extensive set of performance measurements and identify the corresponding main bot- tlenecks; finally we compare the results of our GPU code with those measured on other currently available high performance processors. Our results are a production-grade code able to deliver a sustained performance of several tens of Tflops as well as a design and op- timization methodology that can be used for the development of other high performance applications for computational physics.",cs.DC
1511.03137,k-way Hypergraph Partitioning via n-Level Recursive Bisection,"We develop a multilevel algorithm for hypergraph partitioning that contracts the vertices one at a time. Using several caching and lazy-evaluation techniques during coarsening and refinement, we reduce the running time by up to two-orders of magnitude compared to a naive $n$-level algorithm that would be adequate for ordinary graph partitioning. The overall performance is even better than the widely used hMetis hypergraph partitioner that uses a classical multilevel algorithm with few levels. Aided by a portfolio-based approach to initial partitioning and adaptive budgeting of imbalance within recursive bipartitioning, we achieve very high quality. We assembled a large benchmark set with 310 hypergraphs stemming from application areas such VLSI, SAT solving, social networks, and scientific computing. We achieve significantly smaller cuts than hMetis and PaToH, while being faster than hMetis. Considerably larger improvements are observed for some instance classes like social networks, for bipartitioning, and for partitions with an allowed imbalance of 10%. The algorithm presented in this work forms the basis of our hypergraph partitioning framework KaHyPar (Karlsruhe Hypergraph Partitioning).",cs.DS
1412.7011,Network Synchronization with Convexity,"In this paper, we establish a few new synchronization conditions for complex networks with nonlinear and nonidentical self-dynamics with switching directed communication graphs. In light of the recent works on distributed sub-gradient methods, we impose integral convexity for the nonlinear node self-dynamics in the sense that the self-dynamics of a given node is the gradient of some concave function corresponding to that node. The node couplings are assumed to be linear but with switching directed communication graphs. Several sufficient and/or necessary conditions are established for exact or approximate synchronization over the considered complex networks. These results show when and how nonlinear node self-dynamics may cooperate with the linear diffusive coupling, which eventually leads to network synchronization conditions under relaxed connectivity requirements.",cs.SY
1005.1734,Advanced Radio Resource Management for Multi Antenna Packet Radio Systems,"In this paper, we propose fairness-oriented packet scheduling (PS) schemes with power-efficient control mechanism for future packet radio systems. In general, the radio resource management functionality plays an important role in new OFDMA based networks. The control of the network resource division among the users is performed by packet scheduling functionality based on maximizing cell coverage and capacity satisfying, and certain quality of service requirements. Moreover, multiantenna transmit-receive schemes provide additional flexibility to packet scheduler functionality. In order to mitigate inter-cell and co-channel interference problems in OFDMA cellular networks soft frequency reuse with different power masks patterns is used. Stemming from the earlier enhanced proportional fair scheduler studies for single-input multiple-output (SIMO) and multiple-input multipleoutput (MIMO) systems, we extend the development of efficient packet scheduling algorithms by adding transmit power considerations in the overall priority metrics calculations and scheduling decisions. Furthermore, we evaluate the proposed scheduling schemes by simulating practical orthogonal frequency division multiple access (OFDMA) based packet radio system in terms of throughput, coverage and fairness distribution among users. As a concrete example, under reduced overall transmit power constraint and unequal power distribution for different sub-bands, we demonstrate that by using the proposed power-aware multi-user scheduling schemes, significant coverage and fairness improvements in the order of 70% and 20%, respectively, can be obtained, at the expense of average throughput loss of only 15%.",cs.NI
1407.7594,Monotonic Preference Aggregation Mechanisms for Purchasing a Shareable Resource,"Situations where a group of agents come together to jointly buy a resource that they individually cannot afford to buy are commonly observed in markets. For example in the US market for radio spectrum, a recent proposal invited small firms who would benefit from gaining additional access to spectrum to jointly submit bids for blocks of spectrum with the idea that its utilization could be shared. In such a scenario, the problem is to design a mechanism that truthfully elicits and aggregates the privately held preferences of these agents, and enables them to act as a single decision-making body in order to participate in the market. In this paper, we design a class of mechanisms called monotonic aggregation mechanisms that achieves this under a specific setting. We assume that the resource is being sold in a sealed-bid second-price auction that solicits bids for the entire resource. Our mechanism truthfully elicits utility functions from the buyers, prescribes a joint bid, and prescribes a division of the payment and the resource in the event that they win the resource in the auction. This mechanism further satisfies a popular notion of collusion-resistance known as coalition-strategyproofness. We give two explicit examples of this generic class for the case where the utility functions of the buyers are non-decreasing and concave.",cs.GT
1303.4375,On the Computing of the Minimum Distance of Linear Block Codes by Heuristic Methods,"The evaluation of the minimum distance of linear block codes remains an open problem in coding theory, and it is not easy to determine its true value by classical methods, for this reason the problem has been solved in the literature with heuristic techniques such as genetic algorithms and local search algorithms. In this paper we propose two approaches to attack the hardness of this problem. The first approach is based on genetic algorithms and it yield to good results comparing to another work based also on genetic algorithms. The second approach is based on a new randomized algorithm which we call Multiple Impulse Method MIM, where the principle is to search codewords locally around the all-zero codeword perturbed by a minimum level of noise, anticipating that the resultant nearest nonzero codewords will most likely contain the minimum Hamming-weight codeword whose Hamming weight is equal to the minimum distance of the linear code.",cs.IT math.IT
1808.00216,An AI Based Super Nodes Selection Algorithm in BlockChain Networks,"In blockchain systems, especially cryptographic currencies such as Bitcoin, the double-spending and Byzantine-general-like problem are solved by reaching consensus protocols among all nodes. The state-of-the-art protocols include Proof-of-Work, Proof-of-Stake and Delegated-Proof-of-Stake. Proof-of-Work urges nodes to prove their computing power measured in hash rate in a crypto-puzzle solving competition. The other two take into account the amount of stake of each nodes and even design a vote in Delegated-Proof-of-Stake. However, these frameworks have several drawbacks, such as consuming a large number of electricity, leading the whole blockchain to a centralized system and so on. In this paper, we propose the conceptual framework, fundamental theory and research methodology, based on artificial intelligence technology that exploits nearly complementary information of each nodes. And we designed a particular convolutional neural network and a dynamic threshold, which obtained the super nodes and the random nodes, to reach the consensus. Experimental results demonstrate that our framework combines the advantages of Proof-of-Work, Proof-of-Stake and Delegated-Proof-of-Stake by avoiding complicated hash operation and monopoly. Furthermore, it compares favorably to the three state-of-the-art consensus frameworks, in terms of security and the speed of transaction confirmation.",cs.CR
1310.8187,SmartLoc: Sensing Landmarks Silently for Smartphone Based Metropolitan Localization,"We present \emph{SmartLoc}, a localization system to estimate the location and the traveling distance by leveraging the lower-power inertial sensors embedded in smartphones as a supplementary to GPS. To minimize the negative impact of sensor noises, \emph{SmartLoc} exploits the intermittent strong GPS signals and uses the linear regression to build a prediction model which is based on the trace estimated from inertial sensors and the one computed from the GPS. Furthermore, we utilize landmarks (e.g., bridge, traffic lights) detected automatically and special driving patterns (e.g., turning, uphill, and downhill) from inertial sensory data to improve the localization accuracy when the GPS signal is weak. Our evaluations of \emph{SmartLoc} in the city demonstrates its technique viability and significant localization accuracy improvement compared with GPS and other approaches: the error is approximately 20m for 90% of time while the known mean error of GPS is 42.22m.",cs.NI cs.CY cs.SY
1703.07704,Formal Methods for Adaptive Control of Dynamical Systems,"We develop a method to control discrete-time systems with constant but initially unknown parameters from linear temporal logic (LTL) specifications. We introduce the notions of (non-deterministic) parametric and adaptive transition systems and show how to use tools from formal methods to compute adaptive control strategies for finite systems. For infinite systems, we first compute abstractions in the form of parametric finite quotient transition systems and then apply the techniques for finite systems. Unlike traditional adaptive control methods, our approach is correct by design, does not require a reference model, and can deal with a much wider range of systems and specifications. Illustrative case studies are included.",cs.SY math.OC
1505.03078,SFAMSS: a secure framework for atm machines via secret sharing,"As ATM applications deploy for a banking system, the need to secure communications will become critical. However, multicast protocols do not fit the point-to-point model of most network security protocols which were designed with unicast communications in mind. In recent years, we have seen the emergence and the growing of ATMs (Automatic Teller Machines) in banking systems. Many banks are extending their activity and increasing transactions by using ATMs. ATM will allow them to reach more customers in a cost effective way and to make their transactions fast and efficient. However, communicating in the network must satisfy integrity, privacy, confidentiality, authentication and non-repudiation. Many frameworks have been implemented to provide security in communication and transactions. In this paper, we analyze ATM communication protocol and propose a novel framework for ATM systems that allows entities communicate in a secure way without using a lot of storage. We describe the architecture and operation of SFAMSS in detail. Our framework is implemented with Java and the software architecture, and its components are studied in detailed.",cs.CR
1801.02911,A Stitch in Time Saves Nine -- SPARQL querying of Property Graphs using Gremlin Traversals,"Knowledge graphs have become popular over the past years and frequently rely on the Resource Description Framework (RDF) or Property Graphs (PG) as underlying data models. However, the query languages for these two data models -- SPARQL for RDF and Gremlin for property graph traversal -- are lacking interoperability. We present Gremlinator, a novel SPARQL to Gremlin translator. Gremlinator translates SPARQL queries to Gremlin traversals for executing graph pattern matching queries over graph databases. This allows to access and query a wide variety of Graph Data Management Systems (DMS) using the W3C standardized SPARQL query language and avoid the learning curve of a new Graph Query Language. Gremlin is a system-agnostic traversal language covering both OLTP graph database or OLAP graph processors, thus making it a desirable choice for supporting interoperability wrt. querying Graph DMSs. We present a comprehensive empirical evaluation of Gremlinator and demonstrate its validity and applicability by executing SPARQL queries on top of the leading graph stores Neo4J, Sparksee, and Apache TinkerGraph and compare the performance with the RDF stores Virtuoso, 4Store and JenaTDB. Our evaluation demonstrates the substantial performance gain obtained by the Gremlin counterparts of the SPARQL queries, especially for star-shaped and complex queries.",cs.DB cs.PF
1906.01231,Coherent Comment Generation for Chinese Articles with a Graph-to-Sequence Model,"Automatic article commenting is helpful in encouraging user engagement and interaction on online news platforms. However, the news documents are usually too long for traditional encoder-decoder based models, which often results in general and irrelevant comments. In this paper, we propose to generate comments with a graph-to-sequence model that models the input news as a topic interaction graph. By organizing the article into graph structure, our model can better understand the internal structure of the article and the connection between topics, which makes it better able to understand the story. We collect and release a large scale news-comment corpus from a popular Chinese online news platform Tencent Kuaibao. Extensive experiment results show that our model can generate much more coherent and informative comments compared with several strong baseline models.",cs.CL cs.AI
1507.03040,Tight Risk Bounds for Multi-Class Margin Classifiers,"We consider a problem of risk estimation for large-margin multi-class classifiers. We propose a novel risk bound for the multi-class classification problem. The bound involves the marginal distribution of the classifier and the Rademacher complexity of the hypothesis class. We prove that our bound is tight in the number of classes. Finally, we compare our bound with the related ones and provide a simplified version of the bound for the multi-class classification with kernel based hypotheses.",stat.ML cs.LG
1901.11313,AnomiGAN: Generative adversarial networks for anonymizing private medical data,"Typical personal medical data contains sensitive information about individuals. Storing or sharing the personal medical data is thus often risky. For example, a short DNA sequence can provide information that can not only identify an individual, but also his or her relatives. Nonetheless, most countries and researchers agree on the necessity of collecting personal medical data. This stems from the fact that medical data, including genomic data, are an indispensable resource for further research and development regarding disease prevention and treatment. To prevent personal medical data from being misused, techniques to reliably preserve sensitive information should be developed for real world application. In this paper, we propose a framework called anonymized generative adversarial networks (AnomiGAN), to improve the maintenance of privacy of personal medical data, while also maintaining high prediction performance. We compared our method to state-of-the-art techniques and observed that our method preserves the same level of privacy as differential privacy (DP), but had better prediction results. We also observed that there is a trade-off between privacy and performance results depending on the degree of preservation of the original data. Here, we provide a mathematical overview of our proposed model and demonstrate its validation using UCI machine learning repository datasets in order to highlight its utility in practice. Experimentally, our approach delivers a better performance compared to that of the DP approach.",cs.CR cs.LG
1409.1533,Dynamic Homeostasis in Packet Switching Networks,"In this study, we investigate the adaptation and robustness of a packet switching network (PSN), the fundamental architecture of the Internet. We claim that the adaptation introduced by a transmission control protocol (TCP) congestion control mechanism is interpretable as the self-organization of multiple attractors and stability to switch from one attractor to another. To discuss this argument quantitatively, we study the adaptation of the Internet by simulating a PSN using ns-2. Our hypothesis is that the robustness and fragility of the Internet can be attributed to the inherent dynamics of the PSN feedback mechanism called the congestion window size, or \textit{cwnd}. By varying the data input into the PSN system, we investigate the possible self-organization of attractors in cwnd temporal dynamics and discuss the adaptability and robustness of PSNs. The present study provides an example of Ashby's Law of Requisite Variety in action.",cs.NI physics.soc-ph
1608.03640,MSE-based Precoding for MIMO Downlinks in Heterogeneous Networks,"Considering a heterogeneous network (HetNet) system consisting of a macro tier overlaid with a second tier of small cells (SCs), this paper studies the mean square error (MSE) based precoding design to be employed by the macro base station and the SC nodes for multiple-input multiple-output (MIMO) downlinks. First, a new sum-MSE of all users based minimization problem is proposed aiming to design a set of macro cell (MC) and SC transmit precoding matrices or vectors. To solve it, two different algorithms are presented. One is via a relaxed-constraints based alternating optimization (RAO) realized by efficient alternating optimization and relaxing non-convex constraints to convex ones. The other is via an unconstrained alternating optimization with normalization (UAON) implemented by introducing the constraints into the iterations with the normalization operation. Second, a separate MSE minimization based precoding is proposed by considering the signal and interference terms corresponding to the macro tier and the SCs separately. Simulation results show that the sum-MSE based RAO algorithm provides the best MSE performance among the proposed schemes under a number of system configurations. When the number of antennas at the macro-BS is sufficiently large, the MSE of the separate MSE-based precoding is found to approach that of RAO and surpass that of UAON. Together, this paper provides a suite of three new precoding techniques that is expected to meet the need in a broad range of HetNet environments with adequate balance between performance and complexity.",cs.IT math.IT
cs/0410056,Interval Neutrosophic Logics: Theory and Applications,"In this paper, we present the interval neutrosophic logics which generalizes the fuzzy logic, paraconsistent logic, intuitionistic fuzzy logic and many other non-classical and non-standard logics. We will give the formal definition of interval neutrosophic propositional calculus and interval neutrosophic predicate calculus. Then we give one application of interval neutrosophic logics to do approximate reasoning.",cs.LO
